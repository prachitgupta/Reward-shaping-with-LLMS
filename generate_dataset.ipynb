{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwywg9S6YMtQ",
        "outputId": "24da382f-0e1f-4ab0-fb6b-57fa9f1960d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: highway-env in /usr/local/lib/python3.10/dist-packages (1.10.1)\n",
            "Collecting gymnasium>=1.0.0a2 (from highway-env)\n",
            "  Using cached gymnasium-1.0.0a2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from highway-env) (0.0.4)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from highway-env) (1.26.4)\n",
            "Requirement already satisfied: pygame>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from highway-env) (2.6.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from highway-env) (3.7.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from highway-env) (2.1.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from highway-env) (1.13.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=1.0.0a2->highway-env) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=1.0.0a2->highway-env) (4.12.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->highway-env) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->highway-env) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->highway-env) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->highway-env) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->highway-env) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->highway-env) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->highway-env) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->highway-env) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->highway-env) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->highway-env) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->highway-env) (1.16.0)\n",
            "Using cached gymnasium-1.0.0a2-py3-none-any.whl (954 kB)\n",
            "Installing collected packages: gymnasium\n",
            "  Attempting uninstall: gymnasium\n",
            "    Found existing installation: gymnasium 0.29.1\n",
            "    Uninstalling gymnasium-0.29.1:\n",
            "      Successfully uninstalled gymnasium-0.29.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "stable-baselines3 2.4.0a9 requires gymnasium<0.30,>=0.28.1, but you have gymnasium 1.0.0a2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gymnasium-1.0.0a2\n",
            "Collecting git+https://github.com/DLR-RM/stable-baselines3\n",
            "  Cloning https://github.com/DLR-RM/stable-baselines3 to /tmp/pip-req-build-kzl2pyu3\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/DLR-RM/stable-baselines3 /tmp/pip-req-build-kzl2pyu3\n",
            "  Resolved https://github.com/DLR-RM/stable-baselines3 to commit 512eea923afad6f6da4bb53d72b6ea4c6d856e59\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gymnasium<0.30,>=0.28.1 (from stable_baselines3==2.4.0a9)\n",
            "  Using cached gymnasium-0.29.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3==2.4.0a9) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3==2.4.0a9) (2.4.1+cu121)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable_baselines3==2.4.0a9) (2.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable_baselines3==2.4.0a9) (2.1.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable_baselines3==2.4.0a9) (3.7.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable_baselines3==2.4.0a9) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium<0.30,>=0.28.1->stable_baselines3==2.4.0a9) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3==2.4.0a9) (3.16.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3==2.4.0a9) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3==2.4.0a9) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3==2.4.0a9) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3==2.4.0a9) (2024.6.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3==2.4.0a9) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3==2.4.0a9) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3==2.4.0a9) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3==2.4.0a9) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3==2.4.0a9) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3==2.4.0a9) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3==2.4.0a9) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3==2.4.0a9) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable_baselines3==2.4.0a9) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable_baselines3==2.4.0a9) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3==2.4.0a9) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13->stable_baselines3==2.4.0a9) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->stable_baselines3==2.4.0a9) (1.3.0)\n",
            "Using cached gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "Installing collected packages: gymnasium\n",
            "  Attempting uninstall: gymnasium\n",
            "    Found existing installation: gymnasium 1.0.0a2\n",
            "    Uninstalling gymnasium-1.0.0a2:\n",
            "      Successfully uninstalled gymnasium-1.0.0a2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "highway-env 1.10.1 requires gymnasium>=1.0.0a2, but you have gymnasium 0.29.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gymnasium-0.29.1\n",
            "Requirement already satisfied: tensorboardx in /usr/local/lib/python3.10/dist-packages (2.6.2.2)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.10/dist-packages (3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardx) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardx) (24.1)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardx) (3.20.3)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym) (0.0.8)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "xvfb is already the newest version (2:21.1.4-2ubuntu1.7~22.04.11).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "# # Install environment and agent\n",
        "!pip install highway-env\n",
        "# TODO: we use the bleeding edge version because the current stable version does not support the latest gym>=0.21 versions. Revert back to stable at the next SB3 release.\n",
        "!pip install git+https://github.com/DLR-RM/stable-baselines3\n",
        "\n",
        "# # Environment\n",
        "import gymnasium as gym\n",
        "import highway_env\n",
        "\n",
        "# Agent\n",
        "from stable_baselines3 import DQN\n",
        "\n",
        "\n",
        "import sys\n",
        "from tqdm.notebook import trange\n",
        "!pip install tensorboardx gym pyvirtualdisplay\n",
        "!apt-get install -y xvfb ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YUvBAOIoYMtS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ddef84e-441f-4a7a-f2f7-df6c547e2c47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "from stable_baselines3 import DQN\n",
        "import pprint\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGQ4CGXAYMtT"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GcQ7IlUxYMtT"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "from pathlib import Path\n",
        "\n",
        "from gymnasium.wrappers import RecordVideo\n",
        "from IPython import display as ipythondisplay\n",
        "from pyvirtualdisplay import Display\n",
        "\n",
        "\n",
        "\n",
        "def record_videos(env, video_folder=\"videos\"):\n",
        "    wrapped = RecordVideo(\n",
        "        env, video_folder=video_folder, episode_trigger=lambda e: True\n",
        "    )\n",
        "\n",
        "    # Capture intermediate frames\n",
        "    env.unwrapped.set_record_video_wrapper(wrapped)\n",
        "\n",
        "    return wrapped\n",
        "\n",
        "\n",
        "def show_videos(path=\"videos\"):\n",
        "    html = []\n",
        "    for mp4 in Path(path).glob(\"*.mp4\"):\n",
        "        video_b64 = base64.b64encode(mp4.read_bytes())\n",
        "        html.append(\n",
        "            \"\"\"<video alt=\"{}\" autoplay\n",
        "                      loop controls style=\"height: 400px;\">\n",
        "                      <source src=\"data:video/mp4;base64,{}\" type=\"video/mp4\" />\n",
        "                 </video>\"\"\".format(\n",
        "                mp4, video_b64.decode(\"ascii\")\n",
        "            )\n",
        "        )\n",
        "    ipythondisplay.display(ipythondisplay.HTML(data=\"<br>\".join(html)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "G6GV6Ab8YMtU"
      },
      "outputs": [],
      "source": [
        "## record videos\n",
        "def record_model_videos(env_id, model_name, vehicle_count=10, episodes=3, video_folder='videos'):\n",
        "    # Environment configuration\n",
        "    config = {\n",
        "        \"observation\": {\n",
        "            \"type\": \"Kinematics\",\n",
        "            \"features\": [\"presence\", \"x\", \"y\", \"vx\", \"vy\"],\n",
        "            \"absolute\": True,\n",
        "            \"normalize\": True,\n",
        "            \"vehicles_count\": vehicle_count,\n",
        "            \"see_behind\": True,\n",
        "        },\n",
        "        \"action\": {\n",
        "            \"type\": \"DiscreteMetaAction\",\n",
        "            \"target_speeds\": np.linspace(0, 32, 9),\n",
        "        },\n",
        "        \"duration\": 40,\n",
        "        \"vehicles_density\": 2,\n",
        "        \"show_trajectories\": True,\n",
        "        \"render_agent\": True,\n",
        "    }\n",
        "    ##load model\n",
        "    model = DQN.load(f\"models/{model_name}\")\n",
        "\n",
        "    # Create environment\n",
        "    env = gym.make(env_id, render_mode='rgb_array')\n",
        "    env.configure(config)\n",
        "\n",
        "    # Use RecordVideo wrapper to record videos in the specified folder\n",
        "    video_path = f\"{video_folder}/{model_name}\"\n",
        "    env = RecordVideo(env, video_folder=video_path, episode_trigger=lambda ep: True)\n",
        "\n",
        "    # Loop through the episodes\n",
        "    for episode in trange(episodes, desc=f'Testing {model_name}'):\n",
        "        (obs, info), done, truncated = env.reset(), False, False\n",
        "        while not (done or truncated):\n",
        "            # Replace rf_query with your model prediction function to get action\n",
        "            action, _ = model.predict(obs, deterministic=True)\n",
        "            obs, reward, done, truncated, info = env.step(int(action))\n",
        "\n",
        "    # Close the environment after recording\n",
        "    env.close()\n",
        "\n",
        "    print(f\"Videos saved for {model_name} in {video_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NTuWD8jxYMtU"
      },
      "outputs": [],
      "source": [
        "from stable_baselines3 import DQN\n",
        "import pprint\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0gjbsj1YMtU"
      },
      "source": [
        "llm stuff\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4aaNMKUYMtU"
      },
      "source": [
        "PHI3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OdvyUZjPYMtU"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers huggingface_hub[cli] bitsandbytes accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "BCVSZnNJYMtV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import BitsAndBytesConfig\n",
        "\n",
        "config = BitsAndBytesConfig(\n",
        "   load_in_4bit=True,\n",
        "   bnb_4bit_quant_type=\"nf4\",\n",
        "   bnb_4bit_use_double_quant=True,\n",
        "   bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243,
          "referenced_widgets": [
            "8d2bce70271b481fa386c7329e641ea2",
            "748a55e0e57741ac8bcb2f49f6054d6e",
            "b7b2a9499ee24283ba52919109d769d6",
            "ac0fb30261c54ee9a086a81ede54f42f",
            "9897c5533edc4143abe4e7eaa94aa76c",
            "169aa2b842c541538b5393e94dc06b06",
            "b87d0c0474ba40409b9023972588d383",
            "f7e202d0fb494dd096bf36750ff29991",
            "a855de9d25c64f849079dce1525a9c7a",
            "26b5ea8e459c4fc3bbc73bb779506e27",
            "c6cd8bb092474fab8e3c26b08a60c2bd"
          ]
        },
        "id": "MXl5jZfaYMtV",
        "outputId": "5130bcfe-687c-4277-a804-38e0bafd43de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.0a67737cc96d2554230f90338b163bc6380a2a85.modeling_phi3:`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
            "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.0a67737cc96d2554230f90338b163bc6380a2a85.modeling_phi3:Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8d2bce70271b481fa386c7329e641ea2"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "\n",
        "torch.random.manual_seed(0)\n",
        "\n",
        "llm_model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"microsoft/Phi-3-mini-4k-instruct\",\n",
        "    device_map=\"cuda\",\n",
        "    torch_dtype=\"auto\",\n",
        "    trust_remote_code=True,\n",
        "    quantization_config = config\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Kmj269AqYMtV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae487296-0796-4c84-da06-e4e24a71413a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "def llm_action(prompt1, assist1, prompt2, last_act='FASTER'):\n",
        "\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt1},\n",
        "           {\"role\": \"assistant\", \"content\": assist1},\n",
        "           {\"role\": \"user\", \"content\": prompt2}]\n",
        "\n",
        "    model_inputs = tokenizer.apply_chat_template(messages, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    output = llm_model.generate(model_inputs, max_new_tokens=2000, do_sample=True)\n",
        "\n",
        "    decoded_output = tokenizer.batch_decode(output[:,model_inputs.size(1):], skip_special_tokens=True)\n",
        "\n",
        "    try:\n",
        "        action = decoded_output[0].strip().split('Final decision: ')[1].strip().split('\\'')[0]\n",
        "    except:\n",
        "        action = last_act\n",
        "\n",
        "    return action"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "16XDgKumYMtV"
      },
      "outputs": [],
      "source": [
        "action_dict = {\n",
        "    0: 'LANE_LEFT',\n",
        "    1: 'IDLE',\n",
        "    2: 'LANE_RIGHT',\n",
        "    3: 'FASTER',\n",
        "    4: 'SLOWER'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3RQkZkeYMtV",
        "outputId": "03483adf-b078-4ada-c78f-7d32bf8f89a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:91: DeprecationWarning: invalid escape sequence '\\/'\n"
          ]
        }
      ],
      "source": [
        "class MyHighwayEnv_llm(gym.Env):\n",
        "    def __init__(self, vehicleCount=5):\n",
        "        super(MyHighwayEnv_llm, self).__init__()\n",
        "        # base setting\n",
        "        self.vehicleCount = vehicleCount\n",
        "        self.prev_action  = 'FASTER'\n",
        "\n",
        "        # environment setting\n",
        "        self.config = {\n",
        "            \"observation\": {\n",
        "                \"type\": \"Kinematics\",\n",
        "                \"features\": [\"presence\", \"x\", \"y\", \"vx\", \"vy\"],\n",
        "                \"absolute\": True,\n",
        "                \"normalize\": False,\n",
        "                \"vehicles_count\": vehicleCount,\n",
        "                \"see_behind\": True,\n",
        "            },\n",
        "            \"action\": {\n",
        "                \"type\": \"DiscreteMetaAction\",\n",
        "                \"target_speeds\": np.linspace(0, 32, 9),\n",
        "            },\n",
        "            \"duration\": 40,\n",
        "            \"vehicles_density\": 2,\n",
        "            \"show_trajectories\": True,\n",
        "            \"render_agent\": True,\n",
        "        }\n",
        "        self.env = gym.make(\"highway-v0\")\n",
        "        self.env.configure(self.config)\n",
        "        self.action_space = self.env.action_space\n",
        "        self.observation_space = gym.spaces.Box(\n",
        "            low=-np.inf,high=np.inf,shape=(10,5),dtype=np.float32\n",
        "        )\n",
        "\n",
        "    def find_smallest_positive(self, arr):\n",
        "        smallest_positive = float('inf')\n",
        "        index = -1\n",
        "\n",
        "        for i, value in enumerate(arr):\n",
        "            if 0 < value < smallest_positive:\n",
        "                smallest_positive = value\n",
        "                index = i\n",
        "\n",
        "        return smallest_positive, index\n",
        "\n",
        "    def prompt_design(self, obs_):\n",
        "\n",
        "        prompt1 = 'You are a smart driving assistant. You, the \\'ego\\' car, are now driving on a highway. You need to recommend ONLY ONE best action among the following set of actions based on the current scenario: \\n \\\n",
        "        \\t1. IDLE -- maintain the current speed in the current lane \\n \\\n",
        "        \\t2. FASTER -- accelerate the ego vehicle \\n \\\n",
        "        \\t3. SLOWER -- decelerate the ego vehicle \\n \\\n",
        "        \\t4. LANE_LEFT -- change to the adjacent left lane \\n \\\n",
        "        \\t5. LANE_RIGHT -- change to the adjacent right lane\\n'\n",
        "\n",
        "        assist1 = 'Understood. Please provide the current scenario or conditions, such as traffic density, speed of surrounding vehicles, your current speed, and any other relevant information, so I can recommend the best action.'\n",
        "\n",
        "        prompt2 = 'Here is the current scenario:\\n \\\n",
        "        There are four lanes on the highway: Lane-1 (left most), Lane-2, Lane-3, Lane-4 (right most). \\n\\n'\n",
        "\n",
        "        x, y, vx, vy = obs_[:,1], obs_[:,2], obs_[:,3], obs_[:,4]\n",
        "\n",
        "        ego_x, ego_y   = x[0], y[0]\n",
        "        ego_vx, ego_vy = vx[0], vy[0]\n",
        "\n",
        "        veh_x, veh_y   = x[1:] - ego_x, y[1:] - ego_y\n",
        "        veh_vx, veh_vy = vx[1:], vy[1:]\n",
        "\n",
        "        lanes          = y//4+1\n",
        "        ego_lane       = lanes[0]\n",
        "        veh_lanes      = lanes[1:]\n",
        "\n",
        "        if ego_lane == 1:\n",
        "            ego_left_lane  = 'Left lane: Not available\\n'\n",
        "            ego_right_lane = 'Right lane: Lane-' + str(ego_lane+1) + '\\n'\n",
        "        elif ego_lane == 4:\n",
        "            ego_left_lane  = 'Left lane: Lane-' + str(ego_lane-1) + '\\n'\n",
        "            ego_right_lane = 'Right lane: Not available\\n'\n",
        "        else:\n",
        "            ego_left_lane  = 'Left lane: Lane-' + str(ego_lane-1) + '\\n'\n",
        "            ego_right_lane = 'Right lane: Lane-' + str(ego_lane+1) + '\\n'\n",
        "\n",
        "        prompt2 += 'Ego vehicle:\\n \\\n",
        "        \\tCurrent lane: Lane-' + str(ego_lane) + '\\n' + '\\t' + ego_left_lane + '\\t' + ego_right_lane + '\\tCurrent speed: ' + str(ego_vx) + ' m/s \\n\\n'\n",
        "\n",
        "        lane_info = 'Lane info:\\n'\n",
        "        for i in range(4):\n",
        "            inds     = np.where(veh_lanes == i+1)[0]\n",
        "            num_v    = len(inds)\n",
        "            if num_v > 0:\n",
        "                val, ind = self.find_smallest_positive(veh_x[inds])\n",
        "                true_ind = inds[ind]\n",
        "                lane_info += '\\tLane-' + str(i+1) + ': There are ' + str(num_v) + ' vehicle(s) in this lane ahead of ego vehicle, closest being ' + str(veh_x[true_ind]) + ' m ahead traveling at ' + str(veh_vx[true_ind]) + ' m\\/s. \\n'\n",
        "            else:\n",
        "                lane_info += '\\tLane-' + str(i+1) + ' No other vehicle ahead of ego vehicle.\\n'\n",
        "\n",
        "        prompt2 += lane_info\n",
        "\n",
        "        att_info = '\\nAttention points:\\n \\\n",
        "        \\t1. SLOWER has least priority and should be used only when no other action is safe.\\n \\\n",
        "        \\t2. DO NOT change lanes frequently.\\n \\\n",
        "        \\t3. Safety is priority, but do not forget efficiency.\\n \\\n",
        "        \\t4. Your suggested action has to be one from one of the above five listed actions - IDLE, SLOWER, FASTER, LANE_LEFT, LANE_RIGHT. \\n \\\n",
        "        Your last action was ' + self.prev_action + '. Please recommend action for the current scenario ONLY in the format \\'Final decision: <final decision>\\'.\\n'\n",
        "\n",
        "        prompt2 += att_info\n",
        "\n",
        "\n",
        "        return prompt1, assist1, prompt2\n",
        "\n",
        "    def prompt_design_blog(self, obs_):\n",
        "\n",
        "      # Part 1: Initial prompt introducing the scenario\n",
        "      prompt1 = 'You are Phi3, a large language model. You are now acting as a mature driving assistant, who can give accurate and correct advice for human drivers in complex urban driving scenarios. The information in the current scenario:\\n\\\n",
        "                You, the \\'ego\\' car, are now driving on a highway. You have already driven for 0 seconds.\\n\\\n",
        "                The decision made by the agent LAST time step was \\'FASTER\\' (accelerate the vehicle).'\n",
        "\n",
        "      # Part 2: Driving rules that must be followed\n",
        "      rules = \"There are several rules you need to follow when you drive on a highway:\\n\\\n",
        "              1. Try to keep a safe distance from the car in front of you.\\n\\\n",
        "              2. DON’T change lanes frequently. If you want to change lanes, double-check the safety of vehicles in the target lane.\"\n",
        "\n",
        "      prompt1 += rules\n",
        "\n",
        "      # Part 3: Attention points for decision making\n",
        "      att_points = \"Here are your attention points:\\n\\\n",
        "                    1. You must output a decision when you finish this task. Your final output decision must be unique and not ambiguous. For example, you cannot say \\\"I can either keep lane or accelerate at the current time\\\".\\n\\\n",
        "                    2. You need to always remember your current lane ID, your available actions, and available lanes before you make any decision.\\n\\\n",
        "                    3. Once you have a decision, you should check the safety with all the vehicles affected by your decision.\\n\\\n",
        "                    4. If you verify a decision is unsafe, you should start a new one and verify its safety again from scratch.\"\n",
        "\n",
        "      prompt1 += att_points\n",
        "\n",
        "      # Part 4: Request for additional scenario details\n",
        "      assist1 = 'Understood. Please provide the current scenario or conditions, such as traffic density, speed of surrounding vehicles, your current speed, and any other relevant information, so I can recommend the best action.'\n",
        "\n",
        "      # Part 5: Describing the current highway scenario\n",
        "      prompt2 = 'Here is the current scenario:\\n\\\n",
        "      There are four lanes on the highway: Lane-1 (leftmost), Lane-2, Lane-3, Lane-4 (rightmost).\\n\\n'\n",
        "\n",
        "      # Extract information from the observations\n",
        "      x, y, vx, vy = obs_[:, 1], obs_[:, 2], obs_[:, 3], obs_[:, 4]\n",
        "\n",
        "      # Ego vehicle details\n",
        "      ego_x, ego_y = x[0], y[0]\n",
        "      ego_vx, ego_vy = vx[0], vy[0]\n",
        "\n",
        "      # Other vehicles' relative positions\n",
        "      veh_x, veh_y = x[1:] - ego_x, y[1:] - ego_y\n",
        "      veh_vx, veh_vy = vx[1:], vy[1:]\n",
        "\n",
        "      # Determine lane information for ego and other vehicles\n",
        "      lanes = y // 4 + 1\n",
        "      ego_lane = lanes[0]\n",
        "      veh_lanes = lanes[1:]\n",
        "\n",
        "      # Left and right lane availability based on the ego vehicle's current lane\n",
        "      if ego_lane == 1:\n",
        "          ego_left_lane = 'Left lane: Not available\\n'\n",
        "          ego_right_lane = 'Right lane: Lane-' + str(ego_lane + 1) + '\\n'\n",
        "      elif ego_lane == 4:\n",
        "          ego_left_lane = 'Left lane: Lane-' + str(ego_lane - 1) + '\\n'\n",
        "          ego_right_lane = 'Right lane: Not available\\n'\n",
        "      else:\n",
        "          ego_left_lane = 'Left lane: Lane-' + str(ego_lane - 1) + '\\n'\n",
        "          ego_right_lane = 'Right lane: Lane-' + str(ego_lane + 1) + '\\n'\n",
        "\n",
        "      # Append ego vehicle information to prompt2\n",
        "      prompt2 += 'Ego vehicle:\\n\\\n",
        "      \\tCurrent lane: Lane-' + str(ego_lane) + '\\n' + '\\t' + ego_left_lane + '\\t' + ego_right_lane + '\\tCurrent speed: ' + str(ego_vx) + ' m/s\\n\\n'\n",
        "\n",
        "      # Lane information including vehicles ahead in each lane\n",
        "      lane_info = 'Lane info:\\n'\n",
        "      for i in range(4):\n",
        "          inds = np.where(veh_lanes == i + 1)[0]\n",
        "          num_v = len(inds)\n",
        "          if num_v > 0:\n",
        "              # Find the closest vehicle in the current lane\n",
        "              val, ind = self.find_smallest_positive(veh_x[inds])\n",
        "              true_ind = inds[ind]\n",
        "              lane_info += '\\tLane-' + str(i + 1) + ': There are ' + str(num_v) + ' vehicle(s) in this lane ahead of ego vehicle, closest being ' + str(veh_x[true_ind]) + ' m ahead traveling at ' + str(veh_vx[true_ind]) + ' m/s.\\n'\n",
        "          else:\n",
        "              lane_info += '\\tLane-' + str(i + 1) + ': No other vehicle ahead of ego vehicle.\\n'\n",
        "\n",
        "      # Append lane information to prompt2\n",
        "      prompt2 += lane_info\n",
        "\n",
        "      # Part 6: Adding additional attention points and the final decision instruction\n",
        "      att_info = '\\nAttention points:\\n\\\n",
        "      \\t1. SLOWER has the least priority and should be used only when no other action is safe.\\n\\\n",
        "      \\t2. DO NOT change lanes frequently.\\n\\\n",
        "      \\t3. Safety is a priority, but do not forget efficiency.\\n\\\n",
        "      \\t4. Your suggested action has to be one from the five listed actions - IDLE, SLOWER, FASTER, LANE_LEFT, LANE_RIGHT.\\n\\\n",
        "      Your last action was ' + self.prev_action + '. Please recommend action for the current scenario ONLY in the format \\'Final decision: <final decision>\\'.\\n'\n",
        "\n",
        "      # Append the attention information to prompt2\n",
        "      prompt2 += att_info\n",
        "\n",
        "      # Return the three prompts\n",
        "      return prompt1, assist1, prompt2\n",
        "\n",
        "\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        # Step the wrapped environment and capture all returned values\n",
        "        obs, dqn_reward, done, truncated, info = self.env.step(action)\n",
        "\n",
        "        self.prev_action = action_dict[action]\n",
        "\n",
        "        Reward = 1 / (1 + np.exp(-dqn_reward))\n",
        "\n",
        "        return obs, Reward, done, truncated, info\n",
        "\n",
        "    def reset(self, **kwargs):\n",
        "        obs = self.env.reset(**kwargs)\n",
        "        return obs  # Make sure to return the observation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ev55-YNIYMtW"
      },
      "source": [
        "GENERATE DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "zJcdaYFXYMtW"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import joblib\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "nUceQm3FYMtW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import trange\n",
        "import random\n",
        "\n",
        "def generate_dataset_model(env, model, file_name, episodes=500):\n",
        "    observations = []\n",
        "    actions = []\n",
        "\n",
        "    for episode in trange(episodes, desc=\"Dataset Generation\"):\n",
        "        (obs, info), done, truncated = env.reset(), False, False\n",
        "        while not (done or truncated):\n",
        "            # Generate prompt for LLM\n",
        "            prompt1, assist1, prompt2 = env.prompt_design_blog(obs)\n",
        "            llm_act = llm_action(prompt1, assist1, prompt2, env.prev_action).strip().split('.')[0]\n",
        "\n",
        "            # Convert LLM action to a numerical label\n",
        "            if 'LANE_LEFT' in llm_act:\n",
        "                action_label = 0\n",
        "            elif 'IDLE' in llm_act:\n",
        "                action_label = 1\n",
        "            elif 'LANE_RIGHT' in llm_act:\n",
        "                action_label = 2\n",
        "            elif 'FASTER' in llm_act:\n",
        "                action_label = 3\n",
        "            elif 'SLOWER' in llm_act:\n",
        "                action_label = 4\n",
        "\n",
        "            # Store observation and corresponding LLM action\n",
        "            observations.append(obs.flatten())\n",
        "            actions.append(action_label)\n",
        "\n",
        "            # Predict action using model and step the environment\n",
        "            action, _ = model.predict(obs, deterministic=True)\n",
        "            obs, reward, done, truncated, info = env.step(int(action))\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    observations = np.array(observations)\n",
        "    actions = np.array(actions)\n",
        "\n",
        "    # Save the dataset as a CSV file\n",
        "    data = pd.DataFrame(observations)\n",
        "    data['action'] = actions\n",
        "\n",
        "    # Create a directory to save the dataset if it doesn't exist\n",
        "    dataset_dir = 'datasets'\n",
        "    if not os.path.exists(dataset_dir):\n",
        "        os.makedirs(dataset_dir)\n",
        "\n",
        "    # Save the dataset in the Colab workspace\n",
        "    dataset_path = os.path.join(dataset_dir, file_name)\n",
        "    data.to_csv(dataset_path, index=False)\n",
        "\n",
        "    print(f\"Dataset saved to {dataset_path}\")\n",
        "\n",
        "    return observations, actions\n",
        "\n",
        "def generate_dataset_epsilon(env, model, file_name, episodes=50, epsilon_start=1.0, epsilon_min=0.1, epsilon_decay=0.99):\n",
        "    observations = []\n",
        "    actions = []\n",
        "    epsilon = epsilon_start\n",
        "\n",
        "    for episode in trange(episodes, desc=\"Dataset Generation\"):\n",
        "        (obs, info), done, truncated = env.reset(), False, False\n",
        "        while not (done or truncated):\n",
        "            # Epsilon-greedy action selection\n",
        "            if random.uniform(0, 1) < epsilon:\n",
        "                # Take a random action (exploration)\n",
        "                action = env.action_space.sample()\n",
        "            else:\n",
        "                # Predict action using the model (exploitation)\n",
        "                action, _ = model.predict(obs, deterministic=True)\n",
        "\n",
        "            # Generate prompt for LLM\n",
        "            prompt1, assist1, prompt2 = env.prompt_design_blog(obs)\n",
        "            llm_act = llm_action(prompt1, assist1, prompt2, env.prev_action).strip().split('.')[0]\n",
        "\n",
        "            # Convert LLM action to a numerical label\n",
        "            if 'LANE_LEFT' in llm_act:\n",
        "                action_label = 0\n",
        "            elif 'IDLE' in llm_act:\n",
        "                action_label = 1\n",
        "            elif 'LANE_RIGHT' in llm_act:\n",
        "                action_label = 2\n",
        "            elif 'FASTER' in llm_act:\n",
        "                action_label = 3\n",
        "            elif 'SLOWER' in llm_act:\n",
        "                action_label = 4\n",
        "\n",
        "            # Store observation and corresponding LLM action\n",
        "            observations.append(obs.flatten())\n",
        "            actions.append(action_label)\n",
        "\n",
        "            # Step the environment with the chosen action\n",
        "            obs, reward, done, truncated, info = env.step(int(action))\n",
        "\n",
        "            # Decay epsilon after each episode to reduce exploration over time\n",
        "            epsilon = max(epsilon_min, epsilon * epsilon_decay)\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    observations = np.array(observations)\n",
        "    actions = np.array(actions)\n",
        "\n",
        "    # Save the dataset as a CSV file\n",
        "    data = pd.DataFrame(observations)\n",
        "    data['action'] = actions\n",
        "\n",
        "    # Create a directory to save the dataset if it doesn't exist\n",
        "    if not os.path.exists('datasets'):\n",
        "        os.makedirs('datasets')\n",
        "\n",
        "    # Save the dataset locally\n",
        "    dataset_path = os.path.join('datasets', file_name)\n",
        "    data.to_csv(dataset_path, index=False)\n",
        "\n",
        "    print(f\"Dataset saved to {dataset_path}\")\n",
        "\n",
        "    return observations, actions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OnOtjWjYMtW",
        "outputId": "d51bb18a-cd37-46c2-dd29-3f0497e1fa75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.configure to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.configure` for environment variables or `env.get_wrapper_attr('configure')` that will search the reminding wrappers.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/save_util.py:167: UserWarning: Could not deserialize object lr_schedule. Consider using `custom_objects` argument to replace this object.\n",
            "Exception: Can't get attribute '_function_setstate' on <module 'cloudpickle.cloudpickle' from '/usr/local/lib/python3.10/dist-packages/cloudpickle/cloudpickle.py'>\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/save_util.py:167: UserWarning: Could not deserialize object exploration_schedule. Consider using `custom_objects` argument to replace this object.\n",
            "Exception: Can't get attribute '_function_setstate' on <module 'cloudpickle.cloudpickle' from '/usr/local/lib/python3.10/dist-packages/cloudpickle/cloudpickle.py'>\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/base_class.py:772: UserWarning: You are probably loading a DQN model saved with SB3 < 2.4.0, we truncated the optimizer state so you can save the model again to avoid issues in the future (see https://github.com/DLR-RM/stable-baselines3/pull/1963 for more info). Original error: loaded state dict contains a parameter group that doesn't match the size of optimizer's group \n",
            "Note: the model should still work fine, this only a warning.\n",
            "  warnings.warn(\n",
            "Dataset Generation:   0%|          | 0/50 [00:00<?, ?it/s]The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n",
            "WARNING:transformers_modules.microsoft.Phi-3-mini-4k-instruct.0a67737cc96d2554230f90338b163bc6380a2a85.modeling_phi3:You are not running the flash-attention implementation, expect numerical differences.\n",
            "Dataset Generation:  86%|████████▌ | 43/50 [2:35:16<28:13, 241.89s/it]"
          ]
        }
      ],
      "source": [
        "# Create and configure the environment\n",
        "env = MyHighwayEnv_llm()\n",
        "\n",
        "modelDqn = DQN.load(\"dqn_model_default_fast\")\n",
        "\n",
        "# Generate dataset from environment and LLM\n",
        "observations, actions = generate_dataset_epsilon(env, modelDqn, \"highway_groq.csv\")\n",
        "\n",
        "# Train Random Forest Model\n",
        "# save_path = 'models/random_forest_model_new.pkl'\n",
        "# rf_model = train_xgb_model(observations, actions, save_path)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8d2bce70271b481fa386c7329e641ea2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_748a55e0e57741ac8bcb2f49f6054d6e",
              "IPY_MODEL_b7b2a9499ee24283ba52919109d769d6",
              "IPY_MODEL_ac0fb30261c54ee9a086a81ede54f42f"
            ],
            "layout": "IPY_MODEL_9897c5533edc4143abe4e7eaa94aa76c"
          }
        },
        "748a55e0e57741ac8bcb2f49f6054d6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_169aa2b842c541538b5393e94dc06b06",
            "placeholder": "​",
            "style": "IPY_MODEL_b87d0c0474ba40409b9023972588d383",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "b7b2a9499ee24283ba52919109d769d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7e202d0fb494dd096bf36750ff29991",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a855de9d25c64f849079dce1525a9c7a",
            "value": 2
          }
        },
        "ac0fb30261c54ee9a086a81ede54f42f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26b5ea8e459c4fc3bbc73bb779506e27",
            "placeholder": "​",
            "style": "IPY_MODEL_c6cd8bb092474fab8e3c26b08a60c2bd",
            "value": " 2/2 [00:38&lt;00:00, 18.38s/it]"
          }
        },
        "9897c5533edc4143abe4e7eaa94aa76c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "169aa2b842c541538b5393e94dc06b06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b87d0c0474ba40409b9023972588d383": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7e202d0fb494dd096bf36750ff29991": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a855de9d25c64f849079dce1525a9c7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "26b5ea8e459c4fc3bbc73bb779506e27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6cd8bb092474fab8e3c26b08a60c2bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}