Welcome to the Amazon Bedrock demo.
----------------------------------------------------------------------------------------
INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials
Listing the available foundation models.
INFO:__main__:Got 75 foundation models.

==========================================
 Model: amazon.titan-tg1-large
------------------------------------------
 Name: Titan Text Large
 Provider: Amazon
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-tg1-large
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['ON_DEMAND']
 Response streaming supported: True
==========================================

==========================================
 Model: amazon.titan-image-generator-v1:0
------------------------------------------
 Name: Titan Image Generator G1
 Provider: Amazon
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-image-generator-v1:0
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT', 'IMAGE']
 Output modalities: ['IMAGE']
 Supported customizations: ['FINE_TUNING']
 Supported inference types: ['PROVISIONED']
==========================================

==========================================
 Model: amazon.titan-image-generator-v1
------------------------------------------
 Name: Titan Image Generator G1
 Provider: Amazon
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-image-generator-v1
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT', 'IMAGE']
 Output modalities: ['IMAGE']
 Supported customizations: []
 Supported inference types: ['ON_DEMAND']
==========================================

==========================================
 Model: amazon.titan-image-generator-v2:0
------------------------------------------
 Name: Titan Image Generator G1 v2
 Provider: Amazon
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-image-generator-v2:0
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT', 'IMAGE']
 Output modalities: ['IMAGE']
 Supported customizations: ['FINE_TUNING']
 Supported inference types: ['PROVISIONED', 'ON_DEMAND']
==========================================

==========================================
 Model: amazon.titan-text-premier-v1:0
------------------------------------------
 Name: Titan Text G1 - Premier
 Provider: Amazon
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-premier-v1:0
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['ON_DEMAND']
 Response streaming supported: True
==========================================

==========================================
 Model: amazon.titan-embed-g1-text-02
------------------------------------------
 Name: Titan Text Embeddings v2
 Provider: Amazon
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-g1-text-02
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT']
 Output modalities: ['EMBEDDING']
 Supported customizations: []
 Supported inference types: ['ON_DEMAND']
==========================================

==========================================
 Model: amazon.titan-text-lite-v1:0:4k
------------------------------------------
 Name: Titan Text G1 - Lite
 Provider: Amazon
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-lite-v1:0:4k
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT']
 Output modalities: ['TEXT']
 Supported customizations: ['FINE_TUNING', 'CONTINUED_PRE_TRAINING']
 Supported inference types: ['PROVISIONED']
 Response streaming supported: True
==========================================

==========================================
 Model: amazon.titan-text-lite-v1
------------------------------------------
 Name: Titan Text G1 - Lite
 Provider: Amazon
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-lite-v1
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['ON_DEMAND']
 Response streaming supported: True
==========================================

==========================================
 Model: amazon.titan-text-express-v1:0:8k
------------------------------------------
 Name: Titan Text G1 - Express
 Provider: Amazon
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-express-v1:0:8k
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT']
 Output modalities: ['TEXT']
 Supported customizations: ['FINE_TUNING', 'CONTINUED_PRE_TRAINING']
 Supported inference types: ['PROVISIONED']
 Response streaming supported: True
==========================================

==========================================
 Model: amazon.titan-text-express-v1
------------------------------------------
 Name: Titan Text G1 - Express
 Provider: Amazon
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-text-express-v1
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['ON_DEMAND']
 Response streaming supported: True
==========================================

==========================================
 Model: amazon.titan-embed-text-v1:2:8k
------------------------------------------
 Name: Titan Embeddings G1 - Text
 Provider: Amazon
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-text-v1:2:8k
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT']
 Output modalities: ['EMBEDDING']
 Supported customizations: []
 Supported inference types: ['PROVISIONED']
 Response streaming supported: False
==========================================

==========================================
 Model: amazon.titan-embed-text-v1
------------------------------------------
 Name: Titan Embeddings G1 - Text
 Provider: Amazon
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-text-v1
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT']
 Output modalities: ['EMBEDDING']
 Supported customizations: []
 Supported inference types: ['ON_DEMAND']
 Response streaming supported: False
==========================================

==========================================
 Model: amazon.titan-embed-text-v2:0:8k
------------------------------------------
 Name: Titan Text Embeddings V2
 Provider: Amazon
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-text-v2:0:8k
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT']
 Output modalities: ['EMBEDDING']
 Supported customizations: []
 Supported inference types: []
 Response streaming supported: False
==========================================

==========================================
 Model: amazon.titan-embed-text-v2:0
------------------------------------------
 Name: Titan Text Embeddings V2
 Provider: Amazon
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-text-v2:0
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT']
 Output modalities: ['EMBEDDING']
 Supported customizations: []
 Supported inference types: ['ON_DEMAND']
 Response streaming supported: False
==========================================

==========================================
 Model: amazon.titan-embed-image-v1:0
------------------------------------------
 Name: Titan Multimodal Embeddings G1
 Provider: Amazon
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-image-v1:0
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT', 'IMAGE']
 Output modalities: ['EMBEDDING']
 Supported customizations: ['FINE_TUNING']
 Supported inference types: ['PROVISIONED']
==========================================

==========================================
 Model: amazon.titan-embed-image-v1
------------------------------------------
 Name: Titan Multimodal Embeddings G1
 Provider: Amazon
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-image-v1
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT', 'IMAGE']
 Output modalities: ['EMBEDDING']
 Supported customizations: []
 Supported inference types: ['ON_DEMAND']
==========================================

==========================================
 Model: stability.stable-diffusion-xl-v1:0
------------------------------------------
 Name: SDXL 1.0
 Provider: Stability AI
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/stability.stable-diffusion-xl-v1:0
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT', 'IMAGE']
 Output modalities: ['IMAGE']
 Supported customizations: []
 Supported inference types: ['PROVISIONED']
==========================================

==========================================
 Model: stability.stable-diffusion-xl-v1
------------------------------------------
 Name: SDXL 1.0
 Provider: Stability AI
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/stability.stable-diffusion-xl-v1
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT', 'IMAGE']
 Output modalities: ['IMAGE']
 Supported customizations: []
 Supported inference types: ['ON_DEMAND']
==========================================

==========================================
 Model: ai21.j2-grande-instruct
------------------------------------------
 Name: J2 Grande Instruct
 Provider: AI21 Labs
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-grande-instruct
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['ON_DEMAND']
 Response streaming supported: False
==========================================

==========================================
 Model: ai21.j2-jumbo-instruct
------------------------------------------
 Name: J2 Jumbo Instruct
 Provider: AI21 Labs
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-jumbo-instruct
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['ON_DEMAND']
 Response streaming supported: False
==========================================

==========================================
 Model: ai21.j2-mid
------------------------------------------
 Name: Jurassic-2 Mid
 Provider: AI21 Labs
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-mid
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['ON_DEMAND']
 Response streaming supported: False
==========================================

==========================================
 Model: ai21.j2-mid-v1
------------------------------------------
 Name: Jurassic-2 Mid
 Provider: AI21 Labs
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-mid-v1
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['ON_DEMAND']
 Response streaming supported: False
==========================================

==========================================
 Model: ai21.j2-ultra
------------------------------------------
 Name: Jurassic-2 Ultra
 Provider: AI21 Labs
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-ultra
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['ON_DEMAND']
 Response streaming supported: False
==========================================

==========================================
 Model: ai21.j2-ultra-v1:0:8k
------------------------------------------
 Name: Jurassic-2 Ultra
 Provider: AI21 Labs
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-ultra-v1:0:8k
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['PROVISIONED']
 Response streaming supported: False
==========================================

==========================================
 Model: ai21.j2-ultra-v1
------------------------------------------
 Name: Jurassic-2 Ultra
 Provider: AI21 Labs
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/ai21.j2-ultra-v1
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['ON_DEMAND']
 Response streaming supported: False
==========================================

==========================================
 Model: ai21.jamba-instruct-v1:0
------------------------------------------
 Name: Jamba-Instruct
 Provider: AI21 Labs
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/ai21.jamba-instruct-v1:0
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['ON_DEMAND']
 Response streaming supported: True
==========================================

==========================================
 Model: ai21.jamba-1-5-large-v1:0
------------------------------------------
 Name: Jamba 1.5 Large
 Provider: AI21 Labs
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/ai21.jamba-1-5-large-v1:0
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['ON_DEMAND']
 Response streaming supported: True
==========================================

==========================================
 Model: ai21.jamba-1-5-mini-v1:0
------------------------------------------
 Name: Jamba 1.5 Mini
 Provider: AI21 Labs
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/ai21.jamba-1-5-mini-v1:0
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['ON_DEMAND']
 Response streaming supported: True
==========================================

==========================================
 Model: anthropic.claude-instant-v1:2:100k
------------------------------------------
 Name: Claude Instant
 Provider: Anthropic
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-instant-v1:2:100k
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['PROVISIONED']
 Response streaming supported: True
==========================================

==========================================
 Model: anthropic.claude-instant-v1
------------------------------------------
 Name: Claude Instant
 Provider: Anthropic
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-instant-v1
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['ON_DEMAND']
 Response streaming supported: True
==========================================

==========================================
 Model: anthropic.claude-v2:0:18k
------------------------------------------
 Name: Claude
 Provider: Anthropic
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:0:18k
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['PROVISIONED']
 Response streaming supported: True
==========================================

==========================================
 Model: anthropic.claude-v2:0:100k
------------------------------------------
 Name: Claude
 Provider: Anthropic
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:0:100k
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['PROVISIONED']
 Response streaming supported: True
==========================================

==========================================
 Model: anthropic.claude-v2:1:18k
------------------------------------------
 Name: Claude
 Provider: Anthropic
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:1:18k
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['PROVISIONED']
 Response streaming supported: True
==========================================

==========================================
 Model: anthropic.claude-v2:1:200k
------------------------------------------
 Name: Claude
 Provider: Anthropic
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:1:200k
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['PROVISIONED']
 Response streaming supported: True
==========================================

==========================================
 Model: anthropic.claude-v2:1
------------------------------------------
 Name: Claude
 Provider: Anthropic
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:1
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['ON_DEMAND']
 Response streaming supported: True
==========================================

==========================================
 Model: anthropic.claude-v2
------------------------------------------
 Name: Claude
 Provider: Anthropic
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['ON_DEMAND']
 Response streaming supported: True
==========================================

==========================================
 Model: anthropic.claude-3-sonnet-20240229-v1:0:28k
------------------------------------------
 Name: Claude 3 Sonnet
 Provider: Anthropic
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-sonnet-20240229-v1:0:28k
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT', 'IMAGE']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['PROVISIONED']
 Response streaming supported: True
==========================================

==========================================
 Model: anthropic.claude-3-sonnet-20240229-v1:0:200k
------------------------------------------
 Name: Claude 3 Sonnet
 Provider: Anthropic
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-sonnet-20240229-v1:0:200k
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT', 'IMAGE']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['PROVISIONED']
 Response streaming supported: True
==========================================

==========================================
 Model: anthropic.claude-3-sonnet-20240229-v1:0
------------------------------------------
 Name: Claude 3 Sonnet
 Provider: Anthropic
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-sonnet-20240229-v1:0
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT', 'IMAGE']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['ON_DEMAND']
 Response streaming supported: True
==========================================

==========================================
 Model: anthropic.claude-3-haiku-20240307-v1:0:48k
------------------------------------------
 Name: Claude 3 Haiku
 Provider: Anthropic
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-haiku-20240307-v1:0:48k
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT', 'IMAGE']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['PROVISIONED']
 Response streaming supported: True
==========================================

==========================================
 Model: anthropic.claude-3-haiku-20240307-v1:0:200k
------------------------------------------
 Name: Claude 3 Haiku
 Provider: Anthropic
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-haiku-20240307-v1:0:200k
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT', 'IMAGE']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['PROVISIONED']
 Response streaming supported: True
==========================================

==========================================
 Model: anthropic.claude-3-haiku-20240307-v1:0
------------------------------------------
 Name: Claude 3 Haiku
 Provider: Anthropic
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-haiku-20240307-v1:0
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT', 'IMAGE']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['ON_DEMAND']
 Response streaming supported: True
==========================================

==========================================
 Model: anthropic.claude-3-opus-20240229-v1:0:12k
------------------------------------------
 Name: Claude 3 Opus
 Provider: Anthropic
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-opus-20240229-v1:0:12k
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT', 'IMAGE']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['PROVISIONED']
 Response streaming supported: True
==========================================

==========================================
 Model: anthropic.claude-3-opus-20240229-v1:0:28k
------------------------------------------
 Name: Claude 3 Opus
 Provider: Anthropic
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-opus-20240229-v1:0:28k
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT', 'IMAGE']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['PROVISIONED']
 Response streaming supported: True
==========================================

==========================================
 Model: anthropic.claude-3-opus-20240229-v1:0:200k
------------------------------------------
 Name: Claude 3 Opus
 Provider: Anthropic
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-opus-20240229-v1:0:200k
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT', 'IMAGE']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['PROVISIONED']
 Response streaming supported: True
==========================================

==========================================
 Model: anthropic.claude-3-opus-20240229-v1:0
------------------------------------------
 Name: Claude 3 Opus
 Provider: Anthropic
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-opus-20240229-v1:0
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT', 'IMAGE']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['INFERENCE_PROFILE']
 Response streaming supported: True
==========================================

==========================================
 Model: anthropic.claude-3-5-sonnet-20240620-v1:0
------------------------------------------
 Name: Claude 3.5 Sonnet
 Provider: Anthropic
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-5-sonnet-20240620-v1:0
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT', 'IMAGE']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['ON_DEMAND']
 Response streaming supported: True
==========================================

==========================================
 Model: cohere.command-text-v14:7:4k
------------------------------------------
 Name: Command
 Provider: Cohere
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/cohere.command-text-v14:7:4k
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT']
 Output modalities: ['TEXT']
 Supported customizations: ['FINE_TUNING']
 Supported inference types: ['PROVISIONED']
 Response streaming supported: True
==========================================

==========================================
 Model: cohere.command-text-v14
------------------------------------------
 Name: Command
 Provider: Cohere
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/cohere.command-text-v14
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['ON_DEMAND']
 Response streaming supported: True
==========================================

==========================================
 Model: cohere.command-r-v1:0
------------------------------------------
 Name: Command R
 Provider: Cohere
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/cohere.command-r-v1:0
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['ON_DEMAND']
 Response streaming supported: True
==========================================

==========================================
 Model: cohere.command-r-plus-v1:0
------------------------------------------
 Name: Command R+
 Provider: Cohere
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/cohere.command-r-plus-v1:0
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['ON_DEMAND']
 Response streaming supported: True
==========================================

==========================================
 Model: cohere.command-light-text-v14:7:4k
------------------------------------------
 Name: Command Light
 Provider: Cohere
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/cohere.command-light-text-v14:7:4k
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT']
 Output modalities: ['TEXT']
 Supported customizations: ['FINE_TUNING']
 Supported inference types: ['PROVISIONED']
 Response streaming supported: True
==========================================

==========================================
 Model: cohere.command-light-text-v14
------------------------------------------
 Name: Command Light
 Provider: Cohere
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/cohere.command-light-text-v14
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['ON_DEMAND']
 Response streaming supported: True
==========================================

==========================================
 Model: cohere.embed-english-v3:0:512
------------------------------------------
 Name: Embed English
 Provider: Cohere
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/cohere.embed-english-v3:0:512
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT']
 Output modalities: ['EMBEDDING']
 Supported customizations: []
 Supported inference types: ['PROVISIONED']
 Response streaming supported: False
==========================================

==========================================
 Model: cohere.embed-english-v3
------------------------------------------
 Name: Embed English
 Provider: Cohere
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/cohere.embed-english-v3
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT']
 Output modalities: ['EMBEDDING']
 Supported customizations: []
 Supported inference types: ['ON_DEMAND']
 Response streaming supported: False
==========================================

==========================================
 Model: cohere.embed-multilingual-v3:0:512
------------------------------------------
 Name: Embed Multilingual
 Provider: Cohere
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/cohere.embed-multilingual-v3:0:512
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT']
 Output modalities: ['EMBEDDING']
 Supported customizations: []
 Supported inference types: ['PROVISIONED']
 Response streaming supported: False
==========================================

==========================================
 Model: cohere.embed-multilingual-v3
------------------------------------------
 Name: Embed Multilingual
 Provider: Cohere
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/cohere.embed-multilingual-v3
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT']
 Output modalities: ['EMBEDDING']
 Supported customizations: []
 Supported inference types: ['ON_DEMAND']
 Response streaming supported: False
==========================================

==========================================
 Model: meta.llama2-13b-chat-v1:0:4k
------------------------------------------
 Name: Llama 2 Chat 13B
 Provider: Meta
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/meta.llama2-13b-chat-v1:0:4k
 Lifecycle status: LEGACY
 Input modalities: ['TEXT']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['PROVISIONED']
 Response streaming supported: True
==========================================

==========================================
 Model: meta.llama2-13b-chat-v1
------------------------------------------
 Name: Llama 2 Chat 13B
 Provider: Meta
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/meta.llama2-13b-chat-v1
 Lifecycle status: LEGACY
 Input modalities: ['TEXT']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['ON_DEMAND']
 Response streaming supported: True
==========================================

==========================================
 Model: meta.llama2-70b-chat-v1:0:4k
------------------------------------------
 Name: Llama 2 Chat 70B
 Provider: Meta
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/meta.llama2-70b-chat-v1:0:4k
 Lifecycle status: LEGACY
 Input modalities: ['TEXT']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: []
 Response streaming supported: True
==========================================

==========================================
 Model: meta.llama2-70b-chat-v1
------------------------------------------
 Name: Llama 2 Chat 70B
 Provider: Meta
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/meta.llama2-70b-chat-v1
 Lifecycle status: LEGACY
 Input modalities: ['TEXT']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['ON_DEMAND']
 Response streaming supported: True
==========================================

==========================================
 Model: meta.llama2-13b-v1:0:4k
------------------------------------------
 Name: Llama 2 13B
 Provider: Meta
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/meta.llama2-13b-v1:0:4k
 Lifecycle status: LEGACY
 Input modalities: ['TEXT']
 Output modalities: ['TEXT']
 Supported customizations: ['FINE_TUNING']
 Supported inference types: []
 Response streaming supported: True
==========================================

==========================================
 Model: meta.llama2-13b-v1
------------------------------------------
 Name: Llama 2 13B
 Provider: Meta
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/meta.llama2-13b-v1
 Lifecycle status: LEGACY
 Input modalities: ['TEXT']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: []
 Response streaming supported: True
==========================================

==========================================
 Model: meta.llama2-70b-v1:0:4k
------------------------------------------
 Name: Llama 2 70B
 Provider: Meta
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/meta.llama2-70b-v1:0:4k
 Lifecycle status: LEGACY
 Input modalities: ['TEXT']
 Output modalities: ['TEXT']
 Supported customizations: ['FINE_TUNING']
 Supported inference types: []
 Response streaming supported: True
==========================================

==========================================
 Model: meta.llama2-70b-v1
------------------------------------------
 Name: Llama 2 70B
 Provider: Meta
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/meta.llama2-70b-v1
 Lifecycle status: LEGACY
 Input modalities: ['TEXT']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: []
 Response streaming supported: True
==========================================

==========================================
 Model: meta.llama3-8b-instruct-v1:0
------------------------------------------
 Name: Llama 3 8B Instruct
 Provider: Meta
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-8b-instruct-v1:0
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['ON_DEMAND']
 Response streaming supported: True
==========================================

==========================================
 Model: meta.llama3-70b-instruct-v1:0
------------------------------------------
 Name: Llama 3 70B Instruct
 Provider: Meta
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-70b-instruct-v1:0
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['ON_DEMAND']
 Response streaming supported: True
==========================================

==========================================
 Model: meta.llama3-2-11b-instruct-v1:0
------------------------------------------
 Name: Llama 3.2 11B Instruct
 Provider: Meta
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-2-11b-instruct-v1:0
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT', 'IMAGE']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['INFERENCE_PROFILE']
 Response streaming supported: True
==========================================

==========================================
 Model: meta.llama3-2-90b-instruct-v1:0
------------------------------------------
 Name: Llama 3.2 90B Instruct
 Provider: Meta
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-2-90b-instruct-v1:0
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT', 'IMAGE']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['INFERENCE_PROFILE']
 Response streaming supported: True
==========================================

==========================================
 Model: meta.llama3-2-1b-instruct-v1:0
------------------------------------------
 Name: Llama 3.2 1B Instruct
 Provider: Meta
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-2-1b-instruct-v1:0
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['INFERENCE_PROFILE']
 Response streaming supported: True
==========================================

==========================================
 Model: meta.llama3-2-3b-instruct-v1:0
------------------------------------------
 Name: Llama 3.2 3B Instruct
 Provider: Meta
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-2-3b-instruct-v1:0
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['INFERENCE_PROFILE']
 Response streaming supported: True
==========================================

==========================================
 Model: mistral.mistral-7b-instruct-v0:2
------------------------------------------
 Name: Mistral 7B Instruct
 Provider: Mistral AI
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/mistral.mistral-7b-instruct-v0:2
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['ON_DEMAND']
 Response streaming supported: True
==========================================

==========================================
 Model: mistral.mixtral-8x7b-instruct-v0:1
------------------------------------------
 Name: Mixtral 8x7B Instruct
 Provider: Mistral AI
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/mistral.mixtral-8x7b-instruct-v0:1
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['ON_DEMAND']
 Response streaming supported: True
==========================================

==========================================
 Model: mistral.mistral-large-2402-v1:0
------------------------------------------
 Name: Mistral Large (2402)
 Provider: Mistral AI
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/mistral.mistral-large-2402-v1:0
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['ON_DEMAND']
 Response streaming supported: True
==========================================

==========================================
 Model: mistral.mistral-small-2402-v1:0
------------------------------------------
 Name: Mistral Small
 Provider: Mistral AI
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/mistral.mistral-small-2402-v1:0
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT']
 Output modalities: ['TEXT']
 Supported customizations: []
 Supported inference types: ['ON_DEMAND']
 Response streaming supported: True
==========================================
Getting the details of an individual foundation model.

==========================================
 Model: amazon.titan-embed-text-v1
------------------------------------------
 Name: Titan Embeddings G1 - Text
 Provider: Amazon
 Model ARN: arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-text-v1
 Lifecycle status: ACTIVE
 Input modalities: ['TEXT']
 Output modalities: ['EMBEDDING']
 Supported customizations: []
 Supported inference types: ['ON_DEMAND']
 Response streaming supported: False
==========================================

