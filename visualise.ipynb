{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-17 09:15:24.803078: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-17 09:15:24.852987: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-17 09:15:25.268559: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-17 09:15:26.578379: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import highway_env\n",
    "\n",
    "# Agent\n",
    "from stable_baselines3 import DQN\n",
    "\n",
    "\n",
    "import sys\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "from stable_baselines3 import DQN\n",
    "import pprint\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import joblib\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from pathlib import Path\n",
    "\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "from IPython import display as ipythondisplay\n",
    "from pyvirtualdisplay import Display\n",
    "\n",
    "\n",
    "\n",
    "def record_videos(env, video_folder=\"videos\"):\n",
    "    wrapped = RecordVideo(\n",
    "        env, video_folder=video_folder, episode_trigger=lambda e: True\n",
    "    )\n",
    "\n",
    "    # Capture intermediate frames\n",
    "    env.unwrapped.set_record_video_wrapper(wrapped)\n",
    "\n",
    "    return wrapped\n",
    "\n",
    "\n",
    "def show_videos(path=\"videos\"):\n",
    "    html = []\n",
    "    for mp4 in Path(path).glob(\"*.mp4\"):\n",
    "        video_b64 = base64.b64encode(mp4.read_bytes())\n",
    "        html.append(\n",
    "            \"\"\"<video alt=\"{}\" autoplay\n",
    "                      loop controls style=\"height: 400px;\">\n",
    "                      <source src=\"data:video/mp4;base64,{}\" type=\"video/mp4\" />\n",
    "                 </video>\"\"\".format(\n",
    "                mp4, video_b64.decode(\"ascii\")\n",
    "            )\n",
    "        )\n",
    "    ipythondisplay.display(ipythondisplay.HTML(data=\"<br>\".join(html)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modify obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_dataset(data):\n",
    "    \"\"\"\n",
    "    Extract features from the dataset based on the given criteria.\n",
    "    \"\"\"\n",
    "    processed_data = []\n",
    "\n",
    "    for row in data:\n",
    "        # Ego vehicle features\n",
    "        ego_features = row[:5]\n",
    "        ego_lane = ego_features[2]//4 + 1  # Lane ID of ego vehicle\n",
    "        ego_speed = ego_features[3]  # Speed of ego vehicle\n",
    "\n",
    "        # Other vehicles' features\n",
    "        other_vehicles = row[5:50].reshape(9, 5)  # 9 vehicles, 5 features each\n",
    "        # actions = row[50]\n",
    "        # Separate features of other vehicles\n",
    "        other_lanes = other_vehicles[:, 2] // 4 + 1  # Lane IDs of other vehicles\n",
    "        distances = np.abs(other_vehicles[:, 1] - ego_features[1])  # Distances from ego vehicle\n",
    "        relative_velocities = other_vehicles[:, 3] - ego_speed  # Relative velocities\n",
    "\n",
    "        # Number of vehicles in ego lane and adjacent lanes\n",
    "        vehicles_in_ego_lane = np.sum(other_lanes == ego_lane)\n",
    "        vehicles_in_left_lane = np.sum(other_lanes == ego_lane - 1)\n",
    "        vehicles_in_right_lane = np.sum(other_lanes == ego_lane + 1)\n",
    "\n",
    "        ## Closest vehicles\n",
    "        closest_ego_index = np.where(other_lanes == ego_lane, distances, np.inf).argmin() if vehicles_in_ego_lane !=0 else np.NAN\n",
    "        closest_left_index = np.where(other_lanes == ego_lane - 1, distances, np.inf).argmin() if vehicles_in_left_lane !=0 else np.NAN\n",
    "        closest_right_index = np.where(other_lanes == ego_lane + 1, distances, np.inf).argmin() if vehicles_in_right_lane !=0 else np.NAN\n",
    "\n",
    "        # Distances of other vehicles\n",
    "        ##ego\n",
    "        if np.isnan(closest_ego_index):\n",
    "            closest_in_ego_lane_dist = 10000  # Assign large value for no vehicle\n",
    "        else:\n",
    "            closest_in_ego_lane_dist = distances[closest_ego_index]  \n",
    "        ##left\n",
    "        if np.isnan(closest_left_index):\n",
    "            closest_left_lane_dist = 10000  # Assign default value for no vehicle\n",
    "        else:\n",
    "            closest_left_lane_dist = distances[closest_left_index]  \n",
    "        ##right\n",
    "        if np.isnan(closest_right_index):\n",
    "            closest_right_lane_dist = 10000  # Assign default value for no vehicle\n",
    "        else:\n",
    "            closest_right_lane_dist = distances[closest_right_index]  \n",
    "\n",
    "        ##relative velocities of closest vehicles\n",
    "        ##ego\n",
    "        if np.isnan(closest_ego_index):\n",
    "            relative_velocity_ego_lane = 10000  # Assign large value for no vehicle\n",
    "        else:\n",
    "            relative_velocity_ego_lane = relative_velocities[closest_ego_index]  \n",
    "        ##left\n",
    "        if np.isnan(closest_left_index):\n",
    "            relative_velocity_left_lane = 10000  # Assign large value for no vehicle\n",
    "        else:\n",
    "            relative_velocity_left_lane = relative_velocities[closest_left_index]  \n",
    "        ##right\n",
    "        if np.isnan(closest_right_index):\n",
    "            relative_velocity_right_lane = 10000  # Assign large value for no vehicle\n",
    "        else:\n",
    "            relative_velocity_right_lane = relative_velocities[closest_right_index]  \n",
    "        \n",
    "        # Append computed features\n",
    "        processed_data.append([\n",
    "            vehicles_in_ego_lane,\n",
    "            vehicles_in_left_lane,\n",
    "            vehicles_in_right_lane,\n",
    "            closest_in_ego_lane_dist,\n",
    "            closest_left_lane_dist,\n",
    "            closest_right_lane_dist,\n",
    "            relative_velocity_ego_lane,\n",
    "            relative_velocity_left_lane,\n",
    "            relative_velocity_right_lane\n",
    "        ])\n",
    "\n",
    "    return np.array(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_query(obs):\n",
    "    ##load model\n",
    "    rf_model = joblib.load(\"models_try/rf_test\")\n",
    "    #print(f\"Model loaded\")\n",
    "    ##\n",
    "    obs_flat = obs.flatten() # Flatten and reshape observation\n",
    "    obs_processed = extract_features_from_dataset([obs_flat])[0]\n",
    "    return rf_model.predict(obs_processed)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prachit/.local/lib/python3.8/site-packages/gymnasium/wrappers/monitoring/video_recorder.py:178: UserWarning: \u001b[33mWARN: Unable to save last video! Did you call close()?\u001b[0m\n",
      "  logger.warn(\"Unable to save last video! Did you call close()?\")\n",
      "/home/prachit/.local/lib/python3.8/site-packages/gymnasium/wrappers/record_video.py:94: UserWarning: \u001b[33mWARN: Overwriting existing videos at /home/prachit/Desktop/Reward-shaping-with-LLMS/videos/test_safe_Claude folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n",
      "Test episodes:   0%|          | 0/3 [00:00<?, ?it/s]/home/prachit/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "Test episodes:   0%|          | 0/3 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[ 9.0000000e+00  0.0000000e+00  0.0000000e+00  9.6991897e-02\n  1.0000000e+04  1.0000000e+04 -1.9715577e-02  1.0000000e+04\n  1.0000000e+04].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 56\u001b[0m\n\u001b[1;32m     53\u001b[0m (obs, info), done, truncated \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset(), \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (done \u001b[38;5;129;01mor\u001b[39;00m truncated):\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;66;03m#action = 4 if np.random.rand() < 0.5 else 3\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[43mrf_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     obs, reward, done, truncated, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;28mint\u001b[39m(action))\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# Log the action taken\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[18], line 8\u001b[0m, in \u001b[0;36mrf_query\u001b[0;34m(obs)\u001b[0m\n\u001b[1;32m      6\u001b[0m obs_flat \u001b[38;5;241m=\u001b[39m obs\u001b[38;5;241m.\u001b[39mflatten() \u001b[38;5;66;03m# Flatten and reshape observation\u001b[39;00m\n\u001b[1;32m      7\u001b[0m obs_processed \u001b[38;5;241m=\u001b[39m extract_features_from_dataset([obs_flat])[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrf_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_processed\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:823\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    803\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[1;32m    805\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 823\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    825\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    826\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:865\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    863\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    864\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[0;32m--> 865\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[1;32m    868\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:599\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;124;03mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[1;32m    598\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 599\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[1;32m    601\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/base.py:605\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    603\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 605\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    607\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:938\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    936\u001b[0m     \u001b[38;5;66;03m# If input is 1D raise error\u001b[39;00m\n\u001b[1;32m    937\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 938\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    939\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    940\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    941\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    942\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    943\u001b[0m         )\n\u001b[1;32m    945\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    946\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    947\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    949\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 9.0000000e+00  0.0000000e+00  0.0000000e+00  9.6991897e-02\n  1.0000000e+04  1.0000000e+04 -1.9715577e-02  1.0000000e+04\n  1.0000000e+04].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "from tqdm import trange  # For progress tracking\n",
    "from IPython.display import display, Video\n",
    "\n",
    "# Base setting\n",
    "vehicleCount = 10\n",
    "\n",
    "# Environment configuration\n",
    "config = {\n",
    "    \"observation\": {\n",
    "        \"type\": \"Kinematics\",\n",
    "        \"features\": [\"presence\", \"x\", \"y\", \"vx\", \"vy\"],\n",
    "        \"absolute\": True,\n",
    "        \"normalize\": True,\n",
    "        \"vehicles_count\": vehicleCount,\n",
    "        \"see_behind\": True,\n",
    "    },\n",
    "    \"action\": {\n",
    "        \"type\": \"DiscreteMetaAction\",\n",
    "        \"target_speeds\": np.linspace(0, 32, 9),\n",
    "    },\n",
    "    \"duration\": 40,\n",
    "    \"vehicles_density\": 1,\n",
    "    \"show_trajectories\": True,\n",
    "    \"render_agent\": True,}\n",
    "\n",
    "# Create directory for video storage if it doesn't exist\n",
    "video_dir = 'videos/test_safe_Claude'\n",
    "if not os.path.exists(video_dir):\n",
    "    os.makedirs(video_dir)\n",
    "\n",
    "# Create directory for action predictions storage if it doesn't exist\n",
    "predictions_dir = 'predictions/test_safe_Claude'\n",
    "if not os.path.exists(predictions_dir):\n",
    "    os.makedirs(predictions_dir)\n",
    "\n",
    "# Create and configure environment\n",
    "env = gym.make('highway-v0', render_mode='rgb_array', config=config)\n",
    "\n",
    "# Wrap environment with video recording\n",
    "env = RecordVideo(env, video_folder=video_dir, episode_trigger=lambda episode_id: True)\n",
    "\n",
    "\n",
    "# Run test episodes and record them\n",
    "for episode in trange(3, desc='Test episodes'):\n",
    "    # Prepare to log the actions taken in this episode\n",
    "    actions_file_path = os.path.join(predictions_dir, f'episode_{episode}_actions.txt')\n",
    "    \n",
    "    with open(actions_file_path, 'w') as action_file:\n",
    "        (obs, info), done, truncated = env.reset(), False, False\n",
    "        while not (done or truncated):\n",
    "            #action = 4 if np.random.rand() < 0.5 else 3\n",
    "            action = rf_query(obs)\n",
    "            obs, reward, done, truncated, info = env.step(int(action))\n",
    "            \n",
    "            # Log the action taken\n",
    "            action_file.write(f\"Action: {action}\\n\")\n",
    "env.close()\n",
    "\n",
    "\n",
    "# Display the recorded videos\n",
    "show_videos()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
