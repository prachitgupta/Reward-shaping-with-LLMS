{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CopMTPbUT_CS",
        "outputId": "ae51dd30-aee3-4a6e-a98f-9ddb1ed61642"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/pip:6: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
            "  from pkg_resources import load_entry_point\n",
            "Requirement already satisfied: dask[dataframe] in /home/prachit/.local/lib/python3.8/site-packages (2023.5.0)\n",
            "Requirement already satisfied: click>=8.0 in /home/prachit/.local/lib/python3.8/site-packages (from dask[dataframe]) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle>=1.5.0 in /home/prachit/.local/lib/python3.8/site-packages (from dask[dataframe]) (3.0.0)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /home/prachit/.local/lib/python3.8/site-packages (from dask[dataframe]) (2024.3.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/prachit/.local/lib/python3.8/site-packages (from dask[dataframe]) (23.2)\n",
            "Requirement already satisfied: partd>=1.2.0 in /home/prachit/.local/lib/python3.8/site-packages (from dask[dataframe]) (1.4.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.8/dist-packages (from dask[dataframe]) (6.0)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /home/prachit/.local/lib/python3.8/site-packages (from dask[dataframe]) (0.12.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /home/prachit/.local/lib/python3.8/site-packages (from dask[dataframe]) (6.8.0)\n",
            "Requirement already satisfied: numpy>=1.21; extra == \"dataframe\" in /home/prachit/.local/lib/python3.8/site-packages (from dask[dataframe]) (1.24.3)\n",
            "Requirement already satisfied: pandas>=1.3; extra == \"dataframe\" in /home/prachit/.local/lib/python3.8/site-packages (from dask[dataframe]) (1.5.2)\n",
            "Requirement already satisfied: locket in /home/prachit/.local/lib/python3.8/site-packages (from partd>=1.2.0->dask[dataframe]) (1.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /home/prachit/.local/lib/python3.8/site-packages (from importlib-metadata>=4.13.0->dask[dataframe]) (3.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /home/prachit/.local/lib/python3.8/site-packages (from pandas>=1.3; extra == \"dataframe\"->dask[dataframe]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/prachit/.local/lib/python3.8/site-packages (from pandas>=1.3; extra == \"dataframe\"->dask[dataframe]) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /home/prachit/.local/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas>=1.3; extra == \"dataframe\"->dask[dataframe]) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install dask[dataframe]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "LmWw0qW1TpRu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "import joblib\n",
        "from sklearn.utils import resample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "eq3xeDX_UORS",
        "outputId": "a40ebe00-9923-4111-ceca-faeb0f2e051c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "      <th>action</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>183.19000</td>\n",
              "      <td>8.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>194.19473</td>\n",
              "      <td>4.0</td>\n",
              "      <td>21.000237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>265.84274</td>\n",
              "      <td>4.0</td>\n",
              "      <td>23.942608</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>276.03580</td>\n",
              "      <td>12.0</td>\n",
              "      <td>21.653471</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>183.19193</td>\n",
              "      <td>4.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>193.33936</td>\n",
              "      <td>12.0</td>\n",
              "      <td>22.372660</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>268.07233</td>\n",
              "      <td>8.0</td>\n",
              "      <td>21.526155</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>278.74005</td>\n",
              "      <td>12.0</td>\n",
              "      <td>21.072702</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>179.14096</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>189.85901</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21.343817</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>261.67822</td>\n",
              "      <td>4.0</td>\n",
              "      <td>22.992239</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>272.70175</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21.753092</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>181.36730</td>\n",
              "      <td>12.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>191.84212</td>\n",
              "      <td>12.0</td>\n",
              "      <td>23.029377</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>265.86804</td>\n",
              "      <td>4.0</td>\n",
              "      <td>22.388924</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>277.21878</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.246387</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>182.26968</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>193.87680</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.046627</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>267.40980</td>\n",
              "      <td>12.0</td>\n",
              "      <td>21.269062</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>279.17953</td>\n",
              "      <td>4.0</td>\n",
              "      <td>23.429052</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 51 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     0          1     2     3    4    5          6     7          8    9  ...  \\\n",
              "0  1.0  183.19000   8.0  25.0  0.0  1.0  194.19473   4.0  21.000237  0.0  ...   \n",
              "1  1.0  183.19193   4.0  25.0  0.0  1.0  193.33936  12.0  22.372660  0.0  ...   \n",
              "2  1.0  179.14096   0.0  25.0  0.0  1.0  189.85901   0.0  21.343817  0.0  ...   \n",
              "3  1.0  181.36730  12.0  25.0  0.0  1.0  191.84212  12.0  23.029377  0.0  ...   \n",
              "4  1.0  182.26968   0.0  25.0  0.0  1.0  193.87680   0.0  23.046627  0.0  ...   \n",
              "\n",
              "          41    42         43   44   45         46    47         48   49  \\\n",
              "0  265.84274   4.0  23.942608  0.0  1.0  276.03580  12.0  21.653471  0.0   \n",
              "1  268.07233   8.0  21.526155  0.0  1.0  278.74005  12.0  21.072702  0.0   \n",
              "2  261.67822   4.0  22.992239  0.0  1.0  272.70175   0.0  21.753092  0.0   \n",
              "3  265.86804   4.0  22.388924  0.0  1.0  277.21878   0.0  22.246387  0.0   \n",
              "4  267.40980  12.0  21.269062  0.0  1.0  279.17953   4.0  23.429052  0.0   \n",
              "\n",
              "   action  \n",
              "0       1  \n",
              "1       4  \n",
              "2       4  \n",
              "3       4  \n",
              "4       4  \n",
              "\n",
              "[5 rows x 51 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv(\"datasets/claude_5k.csv\")\n",
        "data.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LF_67sSulGA"
      },
      "source": [
        "Removing constant features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "40yHE-QG1zls",
        "outputId": "b3bdc1a4-d433-489e-83ef-9bbea10d9a3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Columns removed (constant columns): ['0', '3', '4', '5', '9', '10', '14', '15', '19', '20', '24', '25', '29', '30', '34', '35', '39', '40', '44', '45', '49']\n",
            "\n",
            "DataFrame after removing constant columns:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>...</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>action</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>183.19000</td>\n",
              "      <td>8.0</td>\n",
              "      <td>194.19473</td>\n",
              "      <td>4.0</td>\n",
              "      <td>21.000237</td>\n",
              "      <td>204.98465</td>\n",
              "      <td>12.0</td>\n",
              "      <td>23.771336</td>\n",
              "      <td>215.03693</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>255.65020</td>\n",
              "      <td>12.0</td>\n",
              "      <td>22.052850</td>\n",
              "      <td>265.84274</td>\n",
              "      <td>4.0</td>\n",
              "      <td>23.942608</td>\n",
              "      <td>276.03580</td>\n",
              "      <td>12.0</td>\n",
              "      <td>21.653471</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>183.19193</td>\n",
              "      <td>4.0</td>\n",
              "      <td>193.33936</td>\n",
              "      <td>12.0</td>\n",
              "      <td>22.372660</td>\n",
              "      <td>205.07791</td>\n",
              "      <td>12.0</td>\n",
              "      <td>23.945366</td>\n",
              "      <td>214.59790</td>\n",
              "      <td>4.0</td>\n",
              "      <td>...</td>\n",
              "      <td>257.69952</td>\n",
              "      <td>12.0</td>\n",
              "      <td>22.847837</td>\n",
              "      <td>268.07233</td>\n",
              "      <td>8.0</td>\n",
              "      <td>21.526155</td>\n",
              "      <td>278.74005</td>\n",
              "      <td>12.0</td>\n",
              "      <td>21.072702</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>179.14096</td>\n",
              "      <td>0.0</td>\n",
              "      <td>189.85901</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21.343817</td>\n",
              "      <td>200.20409</td>\n",
              "      <td>4.0</td>\n",
              "      <td>23.967997</td>\n",
              "      <td>211.48848</td>\n",
              "      <td>8.0</td>\n",
              "      <td>...</td>\n",
              "      <td>251.82747</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21.182953</td>\n",
              "      <td>261.67822</td>\n",
              "      <td>4.0</td>\n",
              "      <td>22.992239</td>\n",
              "      <td>272.70175</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21.753092</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>181.36730</td>\n",
              "      <td>12.0</td>\n",
              "      <td>191.84212</td>\n",
              "      <td>12.0</td>\n",
              "      <td>23.029377</td>\n",
              "      <td>203.38297</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.421846</td>\n",
              "      <td>212.44893</td>\n",
              "      <td>8.0</td>\n",
              "      <td>...</td>\n",
              "      <td>254.74644</td>\n",
              "      <td>4.0</td>\n",
              "      <td>23.638973</td>\n",
              "      <td>265.86804</td>\n",
              "      <td>4.0</td>\n",
              "      <td>22.388924</td>\n",
              "      <td>277.21878</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.246387</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>182.26968</td>\n",
              "      <td>0.0</td>\n",
              "      <td>193.87680</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.046627</td>\n",
              "      <td>204.48961</td>\n",
              "      <td>12.0</td>\n",
              "      <td>22.147213</td>\n",
              "      <td>215.17357</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>256.54007</td>\n",
              "      <td>0.0</td>\n",
              "      <td>21.266731</td>\n",
              "      <td>267.40980</td>\n",
              "      <td>12.0</td>\n",
              "      <td>21.269062</td>\n",
              "      <td>279.17953</td>\n",
              "      <td>4.0</td>\n",
              "      <td>23.429052</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           1     2          6     7          8         11    12         13  \\\n",
              "0  183.19000   8.0  194.19473   4.0  21.000237  204.98465  12.0  23.771336   \n",
              "1  183.19193   4.0  193.33936  12.0  22.372660  205.07791  12.0  23.945366   \n",
              "2  179.14096   0.0  189.85901   0.0  21.343817  200.20409   4.0  23.967997   \n",
              "3  181.36730  12.0  191.84212  12.0  23.029377  203.38297   0.0  23.421846   \n",
              "4  182.26968   0.0  193.87680   0.0  23.046627  204.48961  12.0  22.147213   \n",
              "\n",
              "          16   17  ...         36    37         38         41    42  \\\n",
              "0  215.03693  0.0  ...  255.65020  12.0  22.052850  265.84274   4.0   \n",
              "1  214.59790  4.0  ...  257.69952  12.0  22.847837  268.07233   8.0   \n",
              "2  211.48848  8.0  ...  251.82747   0.0  21.182953  261.67822   4.0   \n",
              "3  212.44893  8.0  ...  254.74644   4.0  23.638973  265.86804   4.0   \n",
              "4  215.17357  0.0  ...  256.54007   0.0  21.266731  267.40980  12.0   \n",
              "\n",
              "          43         46    47         48  action  \n",
              "0  23.942608  276.03580  12.0  21.653471       1  \n",
              "1  21.526155  278.74005  12.0  21.072702       4  \n",
              "2  22.992239  272.70175   0.0  21.753092       4  \n",
              "3  22.388924  277.21878   0.0  22.246387       4  \n",
              "4  21.269062  279.17953   4.0  23.429052       4  \n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "constant_columns = [col for col in data.columns if data[col].nunique() == 1]\n",
        "\n",
        "# Remove constant columns from the dataframe\n",
        "data_cleaned = data.drop(columns=constant_columns)\n",
        "\n",
        "# Display the updated dataframe without constant columns\n",
        "print(\"\\nColumns removed (constant columns):\", constant_columns)\n",
        "print(\"\\nDataFrame after removing constant columns:\")\n",
        "data_cleaned.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "M7hejgTB3GcW"
      },
      "outputs": [],
      "source": [
        "y = data_cleaned['action']\n",
        "\n",
        "# Extract the features by dropping the target column ('action')\n",
        "X = data_cleaned.drop('action', axis=1)  # axis=1 to drop a column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 699
        },
        "id": "bPpuAea12rEe",
        "outputId": "561d6ab4-4929-489e-c31b-276b8ef1cfd9"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Computing the correlation matrix\n",
        "corr_matrix = X.corr()\n",
        "# Plotting the heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(abs(corr_matrix), annot=False, cmap='coolwarm')\n",
        "plt.title(\"Correlation Heatmap\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "AdbLzstHez7Z"
      },
      "outputs": [],
      "source": [
        "def label_hist(y):\n",
        "  plt.figure(figsize=(10, 6))\n",
        "  plt.hist(y, bins=5, color='blue', alpha=0.7, edgecolor='black')\n",
        "  plt.title('Histogram of Labels')\n",
        "  plt.xlabel('Labels')\n",
        "  plt.ylabel('Frequency')\n",
        "  plt.xticks(np.unique(y))  # Ensure all unique labels are shown on the x-axis\n",
        "  plt.grid(axis='y', alpha=0.75)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGIUb6AfvhqB"
      },
      "source": [
        "case 1 downsampling majority class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "A3zFyNpiwhw3"
      },
      "outputs": [],
      "source": [
        "classes_to_downsample = [1, 4]\n",
        "n_samples = 1000  # Replace with the desired number of samples\n",
        "\n",
        "# Separate the classes to downsample\n",
        "df_class_1 = data[data['action'] == 1]\n",
        "df_class_4 = data[data['action'] == 4]\n",
        "\n",
        "# Downsample class 1\n",
        "df_class_1_downsampled = resample(df_class_1,\n",
        "                                  replace=False,\n",
        "                                  n_samples=n_samples,\n",
        "                                  random_state=42)\n",
        "\n",
        "# Downsample class 4\n",
        "df_class_4_downsampled = resample(df_class_4,\n",
        "                                  replace=False,\n",
        "                                  n_samples=n_samples,\n",
        "                                  random_state=42)\n",
        "\n",
        "# Remove original classes 1 and 4 from the dataset\n",
        "df_remaining = data[~data['action'].isin(classes_to_downsample)]\n",
        "\n",
        "# Concatenate the downsampled classes with the remaining dataset\n",
        "df_final = pd.concat([df_remaining, df_class_1_downsampled, df_class_4_downsampled])\n",
        "\n",
        "# Shuffle the final dataset\n",
        "df_final = df_final.sample(frac=1, random_state=42).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QadKREax5e13"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzRk4ylHwien"
      },
      "source": [
        "case 2 downsaampling majority and upsampling minority using SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "1gItrNBsd2wF",
        "outputId": "3c18d139-3883-4c70-d779-8a681de01aa9"
      },
      "outputs": [],
      "source": [
        "# Split the resampled data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# Apply SMOTEN to handle class imbalance\n",
        "# smote = SMOTENC(['2_0.0', '2_4.0',\n",
        "#        '2_8.0', '2_12.0', '7_0.0', '7_4.0', '7_8.0', '7_12.0', '12_0.0',\n",
        "#        '12_4.0', '12_8.0', '12_12.0', '17_0.0', '17_4.0', '17_8.0', '17_12.0',\n",
        "#        '22_0.0', '22_4.0', '22_8.0', '22_12.0', '27_0.0', '27_4.0', '27_8.0',\n",
        "#        '27_12.0', '32_0.0', '32_4.0', '32_8.0', '32_12.0', '37_0.0', '37_4.0',\n",
        "#        '37_8.0', '37_12.0', '42_0.0', '42_4.0', '42_8.0', '42_12.0', '47_0.0',\n",
        "#        '47_4.0', '47_8.0', '47_12.0'], sampling_strategy=\"auto\",\n",
        "#               k_neighbors=2,\n",
        "#               random_state=42)\n",
        "smote = SMOTE(sampling_strategy=\"auto\",\n",
        "               k_neighbors=2,\n",
        "               random_state=42)\n",
        "X_train, y_train = smote.fit_resample(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPNsEOB60bgR"
      },
      "source": [
        "categorical class,  replaced by 1 hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "gM42ojyu0afb",
        "outputId": "479471fc-f746-49c7-e082-092e38ee087d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Columns with exactly 4 unique values:\n",
            "['2', '7', '12', '17', '22', '27', '32', '37', '42', '47']\n",
            "\n",
            "DataFrame after one-hot encoding:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>6</th>\n",
              "      <th>8</th>\n",
              "      <th>11</th>\n",
              "      <th>13</th>\n",
              "      <th>16</th>\n",
              "      <th>18</th>\n",
              "      <th>21</th>\n",
              "      <th>23</th>\n",
              "      <th>26</th>\n",
              "      <th>...</th>\n",
              "      <th>37_8.0</th>\n",
              "      <th>37_12.0</th>\n",
              "      <th>42_0.0</th>\n",
              "      <th>42_4.0</th>\n",
              "      <th>42_8.0</th>\n",
              "      <th>42_12.0</th>\n",
              "      <th>47_0.0</th>\n",
              "      <th>47_4.0</th>\n",
              "      <th>47_8.0</th>\n",
              "      <th>47_12.0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>183.19000</td>\n",
              "      <td>194.19473</td>\n",
              "      <td>21.000237</td>\n",
              "      <td>204.98465</td>\n",
              "      <td>23.771336</td>\n",
              "      <td>215.03693</td>\n",
              "      <td>22.811483</td>\n",
              "      <td>225.26805</td>\n",
              "      <td>22.593860</td>\n",
              "      <td>235.24017</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>183.19193</td>\n",
              "      <td>193.33936</td>\n",
              "      <td>22.372660</td>\n",
              "      <td>205.07791</td>\n",
              "      <td>23.945366</td>\n",
              "      <td>214.59790</td>\n",
              "      <td>22.783577</td>\n",
              "      <td>225.87688</td>\n",
              "      <td>21.840850</td>\n",
              "      <td>235.90842</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>179.14096</td>\n",
              "      <td>189.85901</td>\n",
              "      <td>21.343817</td>\n",
              "      <td>200.20409</td>\n",
              "      <td>23.967997</td>\n",
              "      <td>211.48848</td>\n",
              "      <td>22.173645</td>\n",
              "      <td>221.21788</td>\n",
              "      <td>21.366537</td>\n",
              "      <td>231.32758</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>181.36730</td>\n",
              "      <td>191.84212</td>\n",
              "      <td>23.029377</td>\n",
              "      <td>203.38297</td>\n",
              "      <td>23.421846</td>\n",
              "      <td>212.44893</td>\n",
              "      <td>21.055992</td>\n",
              "      <td>222.67287</td>\n",
              "      <td>22.360008</td>\n",
              "      <td>232.90494</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>182.26968</td>\n",
              "      <td>193.87680</td>\n",
              "      <td>23.046627</td>\n",
              "      <td>204.48961</td>\n",
              "      <td>22.147213</td>\n",
              "      <td>215.17357</td>\n",
              "      <td>23.664734</td>\n",
              "      <td>226.28976</td>\n",
              "      <td>23.505920</td>\n",
              "      <td>237.27371</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 60 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           1          6          8         11         13         16  \\\n",
              "0  183.19000  194.19473  21.000237  204.98465  23.771336  215.03693   \n",
              "1  183.19193  193.33936  22.372660  205.07791  23.945366  214.59790   \n",
              "2  179.14096  189.85901  21.343817  200.20409  23.967997  211.48848   \n",
              "3  181.36730  191.84212  23.029377  203.38297  23.421846  212.44893   \n",
              "4  182.26968  193.87680  23.046627  204.48961  22.147213  215.17357   \n",
              "\n",
              "          18         21         23         26  ...  37_8.0  37_12.0  42_0.0  \\\n",
              "0  22.811483  225.26805  22.593860  235.24017  ...       0        1       0   \n",
              "1  22.783577  225.87688  21.840850  235.90842  ...       0        1       0   \n",
              "2  22.173645  221.21788  21.366537  231.32758  ...       0        0       0   \n",
              "3  21.055992  222.67287  22.360008  232.90494  ...       0        0       0   \n",
              "4  23.664734  226.28976  23.505920  237.27371  ...       0        0       0   \n",
              "\n",
              "   42_4.0  42_8.0  42_12.0  47_0.0  47_4.0  47_8.0  47_12.0  \n",
              "0       1       0        0       0       0       0        1  \n",
              "1       0       1        0       0       0       0        1  \n",
              "2       1       0        0       1       0       0        0  \n",
              "3       1       0        0       1       0       0        0  \n",
              "4       0       0        1       0       1       0        0  \n",
              "\n",
              "[5 rows x 60 columns]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Identify columns that have exactly 4 unique values\n",
        "columns_with_4_unique = [col for col in data_cleaned.columns if data_cleaned[col].nunique() == 4 and col!='action']\n",
        "\n",
        "# Display columns with 4 unique values\n",
        "print(\"\\nColumns with exactly 4 unique values:\")\n",
        "print(columns_with_4_unique)\n",
        "\n",
        "# One-hot encode the columns with 4 unique values\n",
        "df_encoded = pd.get_dummies(data_cleaned, columns=columns_with_4_unique,dtype=int)\n",
        "\n",
        "# Display the encoded dataframe\n",
        "print(\"\\nDataFrame after one-hot encoding:\")\n",
        "df_encoded.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9yGOurM0s-p",
        "outputId": "0e1a0288-007e-4bc3-8d09-91f922a6e7d1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['1', '6', '8', '11', '13', '16', '18', '21', '23', '26', '28', '31',\n",
              "       '33', '36', '38', '41', '43', '46', '48', 'action', '2_0.0', '2_4.0',\n",
              "       '2_8.0', '2_12.0', '7_0.0', '7_4.0', '7_8.0', '7_12.0', '12_0.0',\n",
              "       '12_4.0', '12_8.0', '12_12.0', '17_0.0', '17_4.0', '17_8.0', '17_12.0',\n",
              "       '22_0.0', '22_4.0', '22_8.0', '22_12.0', '27_0.0', '27_4.0', '27_8.0',\n",
              "       '27_12.0', '32_0.0', '32_4.0', '32_8.0', '32_12.0', '37_0.0', '37_4.0',\n",
              "       '37_8.0', '37_12.0', '42_0.0', '42_4.0', '42_8.0', '42_12.0', '47_0.0',\n",
              "       '47_4.0', '47_8.0', '47_12.0'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_encoded.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2kCjjgl02Rq"
      },
      "source": [
        "class weights if neccessary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "qVwOU-mf02F6"
      },
      "outputs": [],
      "source": [
        "X = df_encoded.drop(columns=['action'])\n",
        "y = df_encoded['action']\n",
        "class_mapping = {0: 0, 1: 1, 2: 2,4:3}\n",
        "y = y.map(class_mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "NPZUvR9ZTxoI"
      },
      "outputs": [],
      "source": [
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_res_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Apply PCA\n",
        "pca = PCA(n_components=0.98)  # Retain 99% of variance\n",
        "X_res_pca = pca.fit_transform(X_res_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "rf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest Model Accuracy: 63.70%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        38\n",
            "           1       0.64      0.81      0.72       489\n",
            "           2       1.00      0.05      0.09        44\n",
            "           3       0.00      0.00      0.00         5\n",
            "           4       0.63      0.56      0.59       424\n",
            "\n",
            "    accuracy                           0.64      1000\n",
            "   macro avg       0.45      0.28      0.28      1000\n",
            "weighted avg       0.63      0.64      0.61      1000\n",
            "\n",
            "Confusion Matrix:\n",
            " [[  0  12   0   0  26]\n",
            " [  0 396   0   0  93]\n",
            " [  0  19   2   0  23]\n",
            " [  0   5   0   0   0]\n",
            " [  3 182   0   0 239]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/prachit/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/prachit/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/prachit/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/prachit/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/prachit/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/home/prachit/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "  # Initialize and train the Random Forest model\n",
        "rf_model = RandomForestClassifier(\n",
        "bootstrap=False,\n",
        "max_depth=30,\n",
        "max_features='sqrt',\n",
        "min_samples_leaf=1,\n",
        "min_samples_split=5,\n",
        "n_estimators=500,\n",
        "random_state=42, class_weight = \"balanced\"\n",
        ")\n",
        "\n",
        "    # # Define the hyperparameters and their values to be searched\n",
        "    # param_grid = {\n",
        "    #     'n_estimators': [100, 500, 1000],  # Number of trees in the forest\n",
        "    #     'max_depth': [10, 20, 30, None],  # Maximum depth of each tree\n",
        "    #     'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split a node\n",
        "    #     'min_samples_leaf': [1, 2, 4],  # Minimum number of samples required in a leaf node\n",
        "    #     'max_features': ['auto', 'sqrt'],  # Number of features to consider when looking for the best split\n",
        "    #     'bootstrap': [True, False]  # Whether bootstrap samples are used when building trees\n",
        "    # }\n",
        "\n",
        "    # # Apply GridSearchCV to search for the best hyperparameters\n",
        "    # grid_search = GridSearchCV(estimator=rf, param_grid=param_grid,\n",
        "    #                         cv=5, n_jobs=-1, verbose=2, scoring='accuracy')\n",
        "\n",
        "    # # Fit the grid search\n",
        "    # grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # # View the best hyperparameters\n",
        "    # print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
        "\n",
        "    #Predict using the best model\n",
        "\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Step 5: Model Evaluation on Test Data\n",
        "y_pred = rf_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Random Forest Model Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Classification report\n",
        "class_report = classification_report(y_test, y_pred, output_dict=True)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "# plt.figure(figsize=(8, 6))\n",
        "# sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=y_test.unique(), yticklabels=y_test.unique())\n",
        "# plt.title('Confusion Matrix')\n",
        "# plt.xlabel('Predicted')\n",
        "# plt.ylabel('Actual')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "336Pts3B1cW1"
      },
      "source": [
        "XGB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "_nvtn3XSXDIZ",
        "outputId": "ddcdac4c-f580-4162-a1ce-bb102d36cb54"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Found input variables with inconsistent numbers of samples: [1000, 9930]",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[23], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m xgb_model\u001b[38;5;241m.\u001b[39mpredict(X_train)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Accuracy score\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxgb Model Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Classification report\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m     ):\n\u001b[0;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    224\u001b[0m     )\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:220\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m--> 220\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:84\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[1;32m     58\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     86\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py:407\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    405\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 407\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    408\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    409\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    410\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1000, 9930]"
          ]
        }
      ],
      "source": [
        "# Initialize and fit the XGBClassifier\n",
        "xgb_model = XGBClassifier()\n",
        "#xgb_model.fit(X_res_pca, y_train)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "# Predict on test data\n",
        "#y_pred = xgb_model.predict(X_test_pca)\n",
        "y_pred = xgb_model.predict(X_train)\n",
        "\n",
        "# Accuracy score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"xgb Model Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Classification report\n",
        "class_report = classification_report(y_test, y_pred, output_dict=True,zero_division=1)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Confusion matrix (optional for further evaluation)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGA4Fhec60lL"
      },
      "source": [
        "CLASS 4 ALMOST CONFUSED WITH EVERY CLASS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqwhAKJYbE-S",
        "outputId": "5f10d806-8075-4820-9eb1-0ea35c275d87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001761 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 5100\n",
            "[LightGBM] [Info] Number of data points in the train set: 9930, number of used features: 20\n",
            "[LightGBM] [Info] Start training from score -1.609438\n",
            "[LightGBM] [Info] Start training from score -1.609438\n",
            "[LightGBM] [Info] Start training from score -1.609438\n",
            "[LightGBM] [Info] Start training from score -1.609438\n",
            "[LightGBM] [Info] Start training from score -1.609438\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "lgbm = LGBMClassifier()\n",
        "rf = RandomForestClassifier()\n",
        "xgb = XGBClassifier()\n",
        "\n",
        "voting_clf = VotingClassifier(estimators=[\n",
        "    ('xgb', xgb), ('rf', rf), ('lgbm', lgbm)],\n",
        "\n",
        "    voting='soft')\n",
        "voting_clf.fit(X_res_pca, y_train)\n",
        "y_pred_ensemble = voting_clf.predict(X_test_pca)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oR15zzSicij_",
        "outputId": "319f5b4c-4122-4077-fb7f-71bf5bb096a0"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[25], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cross_val_score\n\u001b[0;32m----> 2\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_res_pca\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCross-validation scores: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscores\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscores\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:562\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    560\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 562\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m     ):\n\u001b[0;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    224\u001b[0m     )\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:309\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    308\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 309\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:729\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    727\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    728\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 729\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    733\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/xgboost/core.py:738\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    737\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 738\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1531\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[1;32m   1511\u001b[0m model, metric, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(xgb_model, params)\n\u001b[1;32m   1512\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1513\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1514\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1528\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[1;32m   1529\u001b[0m )\n\u001b[0;32m-> 1531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1532\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1534\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1536\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1537\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1539\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[1;32m   1546\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/xgboost/core.py:738\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    737\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 738\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/xgboost/core.py:2113\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2112\u001b[0m     _check_call(\n\u001b[0;32m-> 2113\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2114\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[1;32m   2115\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2116\u001b[0m     )\n\u001b[1;32m   2117\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2118\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(xgb_model, X_res_pca, y_train, cv=5, scoring='accuracy')\n",
        "print(f\"Cross-validation scores: {scores}\")\n",
        "print(f\"Mean accuracy: {scores.mean():.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_slyVutpcq2m",
        "outputId": "5d6f7736-64e2-49bd-9d03-f54ee58044c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "[[  9  10   1  22]\n",
            " [  5 405   3  95]\n",
            " [  0   8   3  25]\n",
            " [ 15 161   3 230]]\n"
          ]
        }
      ],
      "source": [
        "# Confusion matrix (optional for further evaluation)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_ensemble)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fSESsGJFyfK",
        "outputId": "f69ce479-8d3c-4224-c1f2-c7d403efc0c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ensemble Model Accuracy: 65.03%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.31      0.21      0.25        42\n",
            "           1       0.69      0.80      0.74       508\n",
            "           2       0.30      0.08      0.13        36\n",
            "           3       0.62      0.56      0.59       409\n",
            "\n",
            "    accuracy                           0.65       995\n",
            "   macro avg       0.48      0.41      0.43       995\n",
            "weighted avg       0.63      0.65      0.64       995\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Accuracy score\n",
        "accuracy = accuracy_score(y_test, y_pred_ensemble)\n",
        "print(f\"Ensemble Model Accuracy: {accuracy * 100:.2f}%\")\n",
        "class_report = classification_report(y_test, y_pred_ensemble, output_dict=True,zero_division=1)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_ensemble))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jr2qlqlu1gL8"
      },
      "source": [
        "MLP CLASSIFIER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bT0VBJALY8W",
        "outputId": "67373bb2-c712-4065-9dc5-c088f8c77feb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.15      0.29      0.20        38\n",
            "           1       0.53      0.75      0.62       489\n",
            "           2       0.11      0.16      0.13        44\n",
            "           3       0.02      0.60      0.03         5\n",
            "           4       0.00      0.00      0.00       424\n",
            "\n",
            "    accuracy                           0.39      1000\n",
            "   macro avg       0.16      0.36      0.20      1000\n",
            "weighted avg       0.27      0.39      0.32      1000\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "# Create an MLP Classifier with class weights to handle imbalanced classes\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)\n",
        "\n",
        "# Fit the model\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = mlp.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnwpN05Y1i6W"
      },
      "source": [
        "SVC ONE CLASS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9O_O-xTf1nEE",
        "outputId": "fdb2badf-72bb-48e4-e679-1948466174bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.11      0.66      0.19        38\n",
            "           1       0.56      0.24      0.34       489\n",
            "           2       0.10      0.59      0.17        44\n",
            "           3       0.00      0.00      0.00         5\n",
            "           4       0.44      0.18      0.26       424\n",
            "\n",
            "    accuracy                           0.25      1000\n",
            "   macro avg       0.24      0.33      0.19      1000\n",
            "weighted avg       0.47      0.25      0.29      1000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "# Create a Support Vector Classifier with class weights to handle imbalanced classes\n",
        "svc = SVC(kernel='linear', class_weight='balanced', random_state=42)\n",
        "\n",
        "# Fit the model\n",
        "svc.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = svc.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(classification_report(y_test, y_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
