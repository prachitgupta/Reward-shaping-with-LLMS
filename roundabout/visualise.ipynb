{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 01:29:36.387134: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-29 01:29:36.388927: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-29 01:29:36.428071: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-29 01:29:37.184015: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import highway_env\n",
    "\n",
    "# Agent\n",
    "from stable_baselines3 import DQN\n",
    "\n",
    "\n",
    "import sys\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "from stable_baselines3 import DQN\n",
    "import pprint\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import joblib\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from pathlib import Path\n",
    "\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "from IPython import display as ipythondisplay\n",
    "from pyvirtualdisplay import Display\n",
    "\n",
    "\n",
    "\n",
    "def record_videos(env, video_folder=\"videos\"):\n",
    "    wrapped = RecordVideo(\n",
    "        env, video_folder=video_folder, episode_trigger=lambda e: True\n",
    "    )\n",
    "\n",
    "    # Capture intermediate frames\n",
    "    env.unwrapped.set_record_video_wrapper(wrapped)\n",
    "\n",
    "    return wrapped\n",
    "\n",
    "\n",
    "def show_videos(path=\"videos\"):\n",
    "    html = []\n",
    "    for mp4 in Path(path).glob(\"*.mp4\"):\n",
    "        video_b64 = base64.b64encode(mp4.read_bytes())\n",
    "        html.append(\n",
    "            \"\"\"<video alt=\"{}\" autoplay\n",
    "                      loop controls style=\"height: 400px;\">\n",
    "                      <source src=\"data:video/mp4;base64,{}\" type=\"video/mp4\" />\n",
    "                 </video>\"\"\".format(\n",
    "                mp4, video_b64.decode(\"ascii\")\n",
    "            )\n",
    "        )\n",
    "    ipythondisplay.display(ipythondisplay.HTML(data=\"<br>\".join(html)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modify obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_dataset(row,prev_action):\n",
    "    \"\"\"\n",
    "    Extract features from the dataset based on the given criteria.\n",
    "    \"\"\"\n",
    "    processed_data = []\n",
    "\n",
    "    # Ego vehicle features\n",
    "    ego_features = row[:5]\n",
    "    ego_lane =row[29] # Lane ID of ego vehicle\n",
    "    ego_speed = row[4]  # Speed of ego vehicle\n",
    "\n",
    "    # Other vehicles' features\n",
    "    other_vehicles = row[5:25].reshape(4, 5)  # 3 vehicles, 5 features each\n",
    "    actions = row[30]\n",
    "    \n",
    "    # Separate features of other vehicles\n",
    "    other_lanes = row[25:29]  # Lane IDs of other vehicles\n",
    "    distances = np.abs(other_vehicles[:, 2] - ego_features[2])  # Distances from ego vehicle\n",
    "    relative_velocities = other_vehicles[:, 4] - ego_speed  # Relative velocities\n",
    "\n",
    "    # Number of vehicles in ego lane and adjacent lanes\n",
    "    vehicles_in_ego_lane = np.sum(other_lanes == ego_lane)\n",
    "    vehicles_in_left_lane = np.sum(other_lanes == ego_lane - 1)\n",
    "    vehicles_in_right_lane = np.sum(other_lanes == ego_lane + 1)\n",
    "\n",
    "    ## Closest vehicles\n",
    "    closest_ego_index = np.where(other_lanes == ego_lane, distances, np.inf).argmin() if vehicles_in_ego_lane != 0 else np.nan\n",
    "    closest_left_index = np.where(other_lanes == ego_lane - 1, distances, np.inf).argmin() if vehicles_in_left_lane != 0 else np.nan\n",
    "    closest_right_index = np.where(other_lanes == ego_lane + 1, distances, np.inf).argmin() if vehicles_in_right_lane != 0 else np.nan\n",
    "\n",
    "    # Distances of other vehicles\n",
    "    ## Ego lane\n",
    "    if np.isnan(closest_ego_index):\n",
    "        closest_in_ego_lane_dist = 10000  # Assign large value for no vehicle\n",
    "        relative_velocity_ego_lane = 10000\n",
    "    else:\n",
    "        closest_in_ego_lane_dist = distances[closest_ego_index]\n",
    "        relative_velocity_ego_lane = relative_velocities[closest_ego_index]\n",
    "    \n",
    "    ## Left lane\n",
    "    if np.isnan(closest_left_index):\n",
    "        # Check if the left lane is non-existent (i.e., topmost lane)\n",
    "        if ego_lane == 1:\n",
    "            closest_left_lane_dist = 0  # No lane to the left of topmost lane\n",
    "            relative_velocity_left_lane = 0  \n",
    "        else:\n",
    "            closest_left_lane_dist = 10000  # No vehicle in left lane\n",
    "            relative_velocity_left_lane = 10000  # No vehicle in left lane\n",
    "    else:\n",
    "        closest_left_lane_dist = distances[closest_left_index]\n",
    "        relative_velocity_left_lane = relative_velocities[closest_left_index]\n",
    "    \n",
    "    ## Right lane\n",
    "    if np.isnan(closest_right_index):\n",
    "        # Check if the right lane is non-existent (i.e., bottommost lane)\n",
    "        if ego_lane == 4:\n",
    "            closest_right_lane_dist = 0  # No lane to the right of bottommost lane\n",
    "            relative_velocity_right_lane = 0  # No vehicle in non-existent lane\n",
    "        else:\n",
    "            closest_right_lane_dist = 10000  # No vehicle in right lane\n",
    "            relative_velocity_right_lane = 10000  # No vehicle in right lane\n",
    "    else:\n",
    "        closest_right_lane_dist = distances[closest_right_index]\n",
    "        relative_velocity_right_lane = relative_velocities[closest_right_index]\n",
    "\n",
    "    previous_action_1 = data[i - 1, 30] if i > 0 else 0\n",
    "    #previous_action_2 = data[i - 2, 50] if i > 1 else 0\n",
    "        \n",
    "    # Append computed features\n",
    "    processed_data.append([\n",
    "        vehicles_in_ego_lane,\n",
    "        vehicles_in_left_lane,\n",
    "        vehicles_in_right_lane,\n",
    "        closest_in_ego_lane_dist,\n",
    "        closest_left_lane_dist,\n",
    "        closest_right_lane_dist,\n",
    "        relative_velocity_ego_lane,\n",
    "        relative_velocity_left_lane,\n",
    "        relative_velocity_right_lane,\n",
    "        previous_action_1,\n",
    "        #previous_action_2,\n",
    "        actions\n",
    "        ])\n",
    "\n",
    "\n",
    "    return np.array(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_features_from_dataset(row):\n",
    "#     \"\"\"\n",
    "#     Extract features from the dataset based on the given criteria.\n",
    "#     \"\"\"\n",
    "#     processed_data = []\n",
    "\n",
    "#     # Ego vehicle features\n",
    "#     ego_features = row[:5]\n",
    "#     ego_lane = ego_features[2]//4 + 1  # Lane ID of ego vehicle\n",
    "#     ego_speed = ego_features[3]  # Speed of ego vehicle\n",
    "\n",
    "#     # Other vehicles' features\n",
    "#     other_vehicles = row[5:50].reshape(9, 5)  # 9 vehicles, 5 features each\n",
    "#     # actions = row[50]\n",
    "#     # Separate features of other vehicles\n",
    "#     other_lanes = other_vehicles[:, 2] // 4 + 1  # Lane IDs of other vehicles\n",
    "#     distances = np.abs(other_vehicles[:, 1] - ego_features[1])  # Distances from ego vehicle\n",
    "#     relative_velocities = other_vehicles[:, 3] - ego_speed  # Relative velocities\n",
    "\n",
    "#     # Number of vehicles in ego lane and adjacent lanes\n",
    "#     vehicles_in_ego_lane = np.sum(other_lanes == ego_lane)\n",
    "#     vehicles_in_left_lane = np.sum(other_lanes == ego_lane - 1)\n",
    "#     vehicles_in_right_lane = np.sum(other_lanes == ego_lane + 1)\n",
    "\n",
    "#     ## Closest vehicles\n",
    "#     closest_ego_index = np.where(other_lanes == ego_lane, distances, np.inf).argmin() if vehicles_in_ego_lane !=0 else np.NAN\n",
    "#     closest_left_index = np.where(other_lanes == ego_lane - 1, distances, np.inf).argmin() if vehicles_in_left_lane !=0 else np.NAN\n",
    "#     closest_right_index = np.where(other_lanes == ego_lane + 1, distances, np.inf).argmin() if vehicles_in_right_lane !=0 else np.NAN\n",
    "\n",
    "#     # Distances of other vehicles\n",
    "#     ##ego\n",
    "#     if np.isnan(closest_ego_index):\n",
    "#         closest_in_ego_lane_dist = 10000  # Assign large value for no vehicle\n",
    "#     else:\n",
    "#         closest_in_ego_lane_dist = distances[closest_ego_index]  \n",
    "#     ##left\n",
    "#     if np.isnan(closest_left_index):\n",
    "#         closest_left_lane_dist = 10000  # Assign default value for no vehicle\n",
    "#     else:\n",
    "#         closest_left_lane_dist = distances[closest_left_index]  \n",
    "#     ##right\n",
    "#     if np.isnan(closest_right_index):\n",
    "#         closest_right_lane_dist = 10000  # Assign default value for no vehicle\n",
    "#     else:\n",
    "#         closest_right_lane_dist = distances[closest_right_index]  \n",
    "\n",
    "#     ##relative velocities of closest vehicles\n",
    "#     ##ego\n",
    "#     if np.isnan(closest_ego_index):\n",
    "#         relative_velocity_ego_lane = 10000  # Assign large value for no vehicle\n",
    "#     else:\n",
    "#         relative_velocity_ego_lane = relative_velocities[closest_ego_index]  \n",
    "#     ##left\n",
    "#     if np.isnan(closest_left_index):\n",
    "#         relative_velocity_left_lane = 10000  # Assign large value for no vehicle\n",
    "#     else:\n",
    "#         relative_velocity_left_lane = relative_velocities[closest_left_index]  \n",
    "#     ##right\n",
    "#     if np.isnan(closest_right_index):\n",
    "#         relative_velocity_right_lane = 10000  # Assign large value for no vehicle\n",
    "#     else:\n",
    "#         relative_velocity_right_lane = relative_velocities[closest_right_index]  \n",
    "    \n",
    "# # Append computed features\n",
    "#     processed_data.append([\n",
    "#         vehicles_in_ego_lane,\n",
    "#         vehicles_in_left_lane,\n",
    "#         vehicles_in_right_lane,\n",
    "#         closest_in_ego_lane_dist,\n",
    "#         closest_left_lane_dist,\n",
    "#         closest_right_lane_dist,\n",
    "#         relative_velocity_ego_lane,\n",
    "#         relative_velocity_left_lane,\n",
    "#         relative_velocity_right_lane\n",
    "#     ])\n",
    "\n",
    "#     return np.array(processed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate evaluation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(obs,prev_action):\n",
    "    ##load model\n",
    "    #rf_model = joblib.load(\"models_try/rf_test_no_smote\")\n",
    "    #print(f\"Model loaded\")\n",
    "    ##\n",
    "    obs_flat = obs.flatten() # Flatten and reshape observation\n",
    "  \n",
    "    obs_processed = extract_features_from_dataset(obs_flat,prev_action)\n",
    "    #processed_obs.append(obs_processed)\n",
    "    print(obs_processed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_query(obs, prev_action):\n",
    "    # Load the models\n",
    "    rf_model_binary = joblib.load('models_try/binary_rf_model_collision_free_upsampled.pkl')\n",
    "    rf_model_major = joblib.load(\"models_try/major_rf_model_down_upsampled.pkl\")\n",
    "    \n",
    "    obs_flat = obs.flatten()  # Flatten and reshape observation\n",
    "    obs_processed = extract_features_from_dataset(obs_flat, prev_action)\n",
    "    \n",
    "    # Get the binary prediction and probabilities\n",
    "    binary_pred = rf_model_binary.predict(obs_processed)[0]\n",
    "    binary_pred_prob = rf_model_binary.predict_proba(obs_processed)[0]\n",
    "    \n",
    "    # Get the minor or major class prediction and probabilities\n",
    "    if binary_pred == 0:\n",
    "        minor_pred = 2\n",
    "        minor_pred_prob = 1\n",
    "        return [binary_pred, binary_pred_prob, minor_pred, minor_pred_prob]\n",
    "    else:\n",
    "        major_pred = rf_model_major.predict(obs_processed)[0]\n",
    "        major_pred_prob = rf_model_major.predict_proba(obs_processed)[0]\n",
    "        return [binary_pred, binary_pred_prob, major_pred, major_pred_prob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prachit/.local/lib/python3.8/site-packages/gymnasium/wrappers/record_video.py:94: UserWarning: \u001b[33mWARN: Overwriting existing videos at /home/prachit/Desktop/Reward-shaping-with-LLMS/roundabout/videos/roundabout_test folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n",
      "Test episodes:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test episodes:   0%|          | 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 29 is out of bounds for axis 0 with size 25",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 64\u001b[0m\n\u001b[1;32m     62\u001b[0m (obs, info), done, truncated \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset(), \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (done \u001b[38;5;129;01mor\u001b[39;00m truncated):\n\u001b[0;32m---> 64\u001b[0m     Class, Class_prob, action, action_prob \u001b[38;5;241m=\u001b[39m \u001b[43mrf_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m     obs, reward, done, truncated, info \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;28mint\u001b[39m(action))\n\u001b[1;32m     66\u001b[0m     steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[0;32mIn[12], line 7\u001b[0m, in \u001b[0;36mrf_query\u001b[0;34m(obs, prev_action)\u001b[0m\n\u001b[1;32m      4\u001b[0m rf_model_major \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels_try/major_rf_model_down_upsampled.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m obs_flat \u001b[38;5;241m=\u001b[39m obs\u001b[38;5;241m.\u001b[39mflatten()  \u001b[38;5;66;03m# Flatten and reshape observation\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m obs_processed \u001b[38;5;241m=\u001b[39m \u001b[43mextract_features_from_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Get the binary prediction and probabilities\u001b[39;00m\n\u001b[1;32m     10\u001b[0m binary_pred \u001b[38;5;241m=\u001b[39m rf_model_binary\u001b[38;5;241m.\u001b[39mpredict(obs_processed)[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[10], line 9\u001b[0m, in \u001b[0;36mextract_features_from_dataset\u001b[0;34m(row, prev_action)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Ego vehicle features\u001b[39;00m\n\u001b[1;32m      8\u001b[0m ego_features \u001b[38;5;241m=\u001b[39m row[:\u001b[38;5;241m5\u001b[39m]\n\u001b[0;32m----> 9\u001b[0m ego_lane \u001b[38;5;241m=\u001b[39m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m29\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;66;03m# Lane ID of ego vehicle\u001b[39;00m\n\u001b[1;32m     10\u001b[0m ego_speed \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;241m4\u001b[39m]  \u001b[38;5;66;03m# Speed of ego vehicle\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Other vehicles' features\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 29 is out of bounds for axis 0 with size 25"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "from tqdm import trange  # For progress tracking\n",
    "from IPython.display import display, Video\n",
    "import highway_env\n",
    "\n",
    "# Base setting\n",
    "\n",
    "# Environment configuration\n",
    "config = {\n",
    "            \"observation\": {\n",
    "                \"type\": \"Kinematics\",\n",
    "                \"features\": [\"presence\", \"x\", \"y\", \"vx\", \"vy\"],\n",
    "                \"absolute\": True,\n",
    "                \"normalize\": False,\n",
    "                \"see_behind\": True,\n",
    "                \"duration\": 11,\n",
    "                # \"vehicles_count\": 4,\n",
    "                \"features_range\": {\n",
    "                        \"x\": [-100, 100],\n",
    "                        \"y\": [-100, 100],\n",
    "                        \"vx\": [-15, 15],\n",
    "                        \"vy\": [-15, 15],\n",
    "                    },\n",
    "            },\n",
    "            \"action\": {\n",
    "                \"type\": \"DiscreteMetaAction\",\n",
    "                \"target_speeds\": np.linspace(0, 32, 9),\n",
    "            },\n",
    "            \"duration\": 40,\n",
    "            \"vehicles_density\": 2,\n",
    "            \"show_trajectories\": True,\n",
    "            \"render_agent\": True,\n",
    "        }\n",
    "        #\n",
    "\n",
    "# Create directory for video storage if it doesn't exist\n",
    "video_dir = 'videos/roundabout_test'\n",
    "if not os.path.exists(video_dir):\n",
    "    os.makedirs(video_dir)\n",
    "\n",
    "# Create directory for action predictions storage if it doesn't exist\n",
    "predictions_dir = 'predictions/roundabout_test'\n",
    "if not os.path.exists(predictions_dir):\n",
    "    os.makedirs(predictions_dir)\n",
    "\n",
    "# Create and configure environment\n",
    "env = gym.make(\"roundabout-v0\",render_mode='rgb_array', config= config)\n",
    "# Wrap environment with video recording\n",
    "env = RecordVideo(env, video_folder=video_dir, episode_trigger=lambda episode_id: True)\n",
    "\n",
    "prev_action = 4\n",
    "steps = 0\n",
    "# Run test episodes and record them\n",
    "for episode in trange(5, desc='Test episodes'):\n",
    "    # Prepare to log the actions taken in this episode\n",
    "    actions_file_path = os.path.join(predictions_dir, f'episode_{episode}_actions_normal.txt')\n",
    "    \n",
    "    with open(actions_file_path, 'w') as action_file:\n",
    "        (obs, info), done, truncated = env.reset(), False, False\n",
    "        while not (done or truncated):\n",
    "            Class, Class_prob, action, action_prob = rf_query(obs, prev_action)\n",
    "            obs, reward, done, truncated, info = env.step(int(action))\n",
    "            steps += 1\n",
    "            \n",
    "            # Log the action and probabilities\n",
    "            action_file.write(f\"Class = {Class}  (Probability: {Class_prob})  Action: {action} (Probability: {action_prob})\\n\")\n",
    "        \n",
    "            prev_action = action\n",
    "        print(steps)\n",
    "    \n",
    "env.close()\n",
    "\n",
    "\n",
    "# Display the recorded videos\n",
    "show_videos()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
