{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils import resample\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data merged and sorted successfully. Saved to datasets_try/collision_free.csv\n"
     ]
    }
   ],
   "source": [
    "def merge_and_sort_csv(file1, file2, output_file):\n",
    "    # Load the CSV files into pandas DataFrames\n",
    "    df1 = pd.read_csv(file1)\n",
    "    df2 = pd.read_csv(file2)\n",
    "    #df3 = pd.read_csv(file3)\n",
    "\n",
    "    # Combine the data from both DataFrames\n",
    "    combined_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "    # Sort the combined data by the 'action' column (ascending order)\n",
    "    sorted_df = combined_df.sort_values(by='action', ascending=True)\n",
    "\n",
    "    # Save the sorted data to a new CSV file\n",
    "    sorted_df.to_csv(output_file, index=False)\n",
    "\n",
    "    print(f\"Data merged and sorted successfully. Saved to {output_file}\")\n",
    "\n",
    "# Example usage\n",
    "file1 = 'datasets_try/processed_features_ml_cl.csv'  # Path to your first CSV file\n",
    "file2 = 'datasets_try/processed_features_all_cl.csv'  # Path to your second CSV file\n",
    "#file3 = 'datasets_try/processed_features_5k.csv'\n",
    "# file4 = 'datasets_try/processed_features_el.csv' \n",
    "output_file = 'datasets_try/collision_free.csv'  # Output CSV file\n",
    "\n",
    "merge_and_sort_csv(file1, file2, output_file)\n",
    "\n",
    "##add more datapoints \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0    2470\n",
      "4.0    1567\n",
      "3.0    1424\n",
      "2.0     411\n",
      "0.0     317\n",
      "Name: action, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "collision_free_data = pd.read_csv('datasets_try/collision_free.csv')\n",
    "\n",
    "# Check the distribution of the 'action' column\n",
    "action_distribution = collision_free_data['action'].value_counts()\n",
    "print(action_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UPSAMPLE MINORITY using dataset fromrandomly generated cenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed and saved the data. Merged dataset saved at: datasets_try/collision_free.csv\n",
      "1.0    2470\n",
      "4.0    1567\n",
      "3.0    1424\n",
      "2.0     611\n",
      "0.0     506\n",
      "Name: action, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Load the dataset from the file\n",
    "file_path = 'datasets_try/processed_features_5k.csv'\n",
    "file_path2 = 'datasets_try/processed_features_el_cl.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Step 2: Sort the dataset by the action label (last column)\n",
    "# Assuming the action label is the last column\n",
    "df_sorted = df.sort_values(by='action', ascending=True)\n",
    "\n",
    "# Step 3: Extract data points with action label 0 and 2\n",
    "df_label_0 = df_sorted[df_sorted[df.columns[-1]] == 0]\n",
    "df_label_2 = df_sorted[df_sorted[df.columns[-1]] == 2]\n",
    "\n",
    "# Step 4: Save the filtered data to separate CSV files\n",
    "file_label_0 = 'datasets_try/label_0_data.csv'\n",
    "file_label_2 = 'datasets_try/label_2_data.csv'\n",
    "\n",
    "df_label_0.to_csv(file_label_0, index=False)\n",
    "df_label_2.to_csv(file_label_2, index=False)\n",
    "\n",
    "# Step 5: Extract 200 data points from each new CSV and merge them into another CSV\n",
    "# Load the previously saved files\n",
    "df_label_0_loaded = pd.read_csv(file_label_0)\n",
    "df_label_2_loaded = pd.read_csv(file_label_2)\n",
    "\n",
    "# Randomly select 200 data points from each\n",
    "df_label_0_sampled = df_label_0_loaded.sample(n=189, random_state=42)\n",
    "df_label_2_sampled = df_label_2_loaded.sample(n=200, random_state=42)\n",
    "\n",
    "# Step 6: Merge the two sampled dataframes\n",
    "merged_df = pd.concat([df_label_0_sampled, df_label_2_sampled])\n",
    "\n",
    "# Step 7: Load the existing merged dataset if it exists or create a new one\n",
    "input_file_path = 'datasets_try/collision_free.csv'\n",
    "\n",
    "try:\n",
    "    collision_free_data = pd.read_csv(input_file_path)\n",
    "    # Append the new merged data to the existing one\n",
    "    collision_free_data_upsampled = pd.concat([collision_free_data, merged_df])\n",
    "except FileNotFoundError:\n",
    "    # If the file does not exist, create a new one\n",
    "    collision_free_data = merged_df\n",
    "\n",
    "# Step 8: Save the merged data back into the CSV\n",
    "collision_free_data.to_csv('datasets_try/collision_free_upsampled.csv', index=False)\n",
    "\n",
    "print(f\"Successfully processed and saved the data. Merged dataset saved at: {merged_file_path}\")\n",
    "\n",
    "action_distribution = collision_free_data_upsampled['action'].value_counts()\n",
    "print(action_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Classifier Accuracy on Test Data: 93.31%\n",
      "Precision on Test Data: 94.28%\n",
      "Recall on Test Data: 97.77%\n",
      "F1-Score on Test Data: 95.99%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.73      0.80       119\n",
      "           1       0.94      0.98      0.96       539\n",
      "\n",
      "    accuracy                           0.93       658\n",
      "   macro avg       0.91      0.85      0.88       658\n",
      "weighted avg       0.93      0.93      0.93       658\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 87  32]\n",
      " [ 12 527]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models_try/binary_rf_model_collision_free_upsampled.pkl']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a binary target variable\n",
    "collision_free_data_upsampled['binary_target'] = collision_free_data_upsampled['action'].apply(lambda x: 1 if x in [1,3, 4] else 0)\n",
    "\n",
    "# Split the data into features and binary target\n",
    "X_binary = collision_free_data_upsampled.drop(columns=['action', 'binary_target'])\n",
    "y_binary = collision_free_data_upsampled['binary_target']\n",
    "\n",
    "# Split the dataset into train, test, and eval sets\n",
    "X_train_binary, X_temp_binary, y_train_binary, y_temp_binary = train_test_split(X_binary, y_binary, test_size=0.2, random_state=42)\n",
    "X_test_binary, X_eval_binary, y_test_binary, y_eval_binary = train_test_split(X_temp_binary, y_temp_binary, test_size=0.5, random_state=42)\n",
    "\n",
    "# Train the binary classifier\n",
    "binary_rf_model = RandomForestClassifier(random_state=42)\n",
    "binary_rf_model.fit(X_train_binary, y_train_binary)\n",
    "\n",
    "# Evaluate the binary classifier\n",
    "y_pred_binary_test = binary_rf_model.predict(X_test_binary)\n",
    "accuracy_binary_test = accuracy_score(y_test_binary, y_pred_binary_test)\n",
    "print(f\"Binary Classifier Accuracy on Test Data: {accuracy_binary_test * 100:.2f}%\")\n",
    "# Calculate precision, recall, and F1-score\n",
    "precision_test = precision_score(y_test_binary, y_pred_binary_test)\n",
    "recall_test = recall_score(y_test_binary, y_pred_binary_test)\n",
    "f1_test = f1_score(y_test_binary, y_pred_binary_test)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Precision on Test Data: {precision_test * 100:.2f}%\")\n",
    "print(f\"Recall on Test Data: {recall_test * 100:.2f}%\")\n",
    "print(f\"F1-Score on Test Data: {f1_test * 100:.2f}%\")\n",
    "\n",
    "# Generate a detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_binary, y_pred_binary_test))\n",
    "\n",
    "# Generate a confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test_binary, y_pred_binary_test))\n",
    "\n",
    "# Save the binary classifier\n",
    "joblib.dump(binary_rf_model, 'models_try/binary_rf_model_collision_free_upsampled.pkl')\n",
    "#print(data[5:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0    1567\n",
      "1.0    1500\n",
      "3.0    1424\n",
      "2.0     611\n",
      "0.0     506\n",
      "Name: action, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "collision_free_data_upsampled['binary_target'] = collision_free_data_upsampled['action'].apply(lambda x: 1 if x in [1, 3,4] else 0)\n",
    "\n",
    "# Separate majority and minority classes\n",
    "majority_class = collision_free_data_upsampled[collision_free_data_upsampled['binary_target'] == 1]\n",
    "minority_class = collision_free_data_upsampled[collision_free_data_upsampled['binary_target'] == 0]\n",
    "idle_class = collision_free_data_upsampled[collision_free_data_upsampled['action'] == 1]\n",
    "non_ideal_class = collision_free_data_upsampled[collision_free_data_upsampled['action'] != 1]\n",
    "\n",
    "# Downsample majority class\n",
    "idle_downsampled = resample(idle_class, \n",
    "                                replace=True,    # Sample without replacement\n",
    "                                n_samples=1500,  # Match minority class size\n",
    "                                random_state=42)\n",
    "collision_free_data_up_downsampled = pd.concat([idle_downsampled, non_ideal_class])\n",
    "\n",
    "print(collision_free_data_up_downsampled['action'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Classifier Accuracy on Test Data: 93.40%\n",
      "Precision on Test Data: 93.99%\n",
      "Recall on Test Data: 97.99%\n",
      "F1-Score on Test Data: 95.95%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.75      0.82       114\n",
      "           1       0.94      0.98      0.96       447\n",
      "\n",
      "    accuracy                           0.93       561\n",
      "   macro avg       0.92      0.87      0.89       561\n",
      "weighted avg       0.93      0.93      0.93       561\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 86  28]\n",
      " [  9 438]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models_try/binary_rf_model_collision_free_up_down.pkl']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a binary target variable\n",
    "collision_free_data_up_downsampled['binary_target'] = collision_free_data_up_downsampled['action'].apply(lambda x: 1 if x in [1,3, 4] else 0)\n",
    "\n",
    "# Split the data into features and binary target\n",
    "X_binary = collision_free_data_up_downsampled.drop(columns=['action', 'binary_target'])\n",
    "y_binary = collision_free_data_up_downsampled['binary_target']\n",
    "\n",
    "# Split the dataset into train, test, and eval sets\n",
    "X_train_binary, X_temp_binary, y_train_binary, y_temp_binary = train_test_split(X_binary, y_binary, test_size=0.2, random_state=42)\n",
    "X_test_binary, X_eval_binary, y_test_binary, y_eval_binary = train_test_split(X_temp_binary, y_temp_binary, test_size=0.5, random_state=42)\n",
    "\n",
    "# Train the binary classifier\n",
    "binary_rf_model = RandomForestClassifier(random_state=42)\n",
    "binary_rf_model.fit(X_train_binary, y_train_binary)\n",
    "\n",
    "# Evaluate the binary classifier\n",
    "y_pred_binary_test = binary_rf_model.predict(X_test_binary)\n",
    "accuracy_binary_test = accuracy_score(y_test_binary, y_pred_binary_test)\n",
    "print(f\"Binary Classifier Accuracy on Test Data: {accuracy_binary_test * 100:.2f}%\")\n",
    "# Calculate precision, recall, and F1-score\n",
    "precision_test = precision_score(y_test_binary, y_pred_binary_test)\n",
    "recall_test = recall_score(y_test_binary, y_pred_binary_test)\n",
    "f1_test = f1_score(y_test_binary, y_pred_binary_test)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Precision on Test Data: {precision_test * 100:.2f}%\")\n",
    "print(f\"Recall on Test Data: {recall_test * 100:.2f}%\")\n",
    "print(f\"F1-Score on Test Data: {f1_test * 100:.2f}%\")\n",
    "\n",
    "# Generate a detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_binary, y_pred_binary_test))\n",
    "\n",
    "# Generate a confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test_binary, y_pred_binary_test))\n",
    "\n",
    "# Save the binary classifier\n",
    "joblib.dump(binary_rf_model, 'models_try/binary_rf_model_collision_free_up_down.pkl')\n",
    "#print(data[5:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prachit/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [19:10:44] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy on Test Data: 87.86%\n",
      "Precision on Test Data: 91.21%\n",
      "Recall on Test Data: 95.25%\n",
      "F1-Score on Test Data: 93.18%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.38      0.44        90\n",
      "           1       0.91      0.95      0.93       610\n",
      "\n",
      "    accuracy                           0.88       700\n",
      "   macro avg       0.73      0.67      0.69       700\n",
      "weighted avg       0.86      0.88      0.87       700\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 34  56]\n",
      " [ 29 581]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models_try/xgb_model.pkl']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Initialize the XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Train the model\n",
    "xgb_model.fit(X_train_binary, y_train_binary)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_test = xgb_model.predict(X_test_binary)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_test = accuracy_score(y_test_binary, y_pred_test)\n",
    "precision_test = precision_score(y_test_binary, y_pred_test)\n",
    "recall_test = recall_score(y_test_binary, y_pred_test)\n",
    "f1_test = f1_score(y_test_binary, y_pred_test)\n",
    "\n",
    "print(f\"XGBoost Accuracy on Test Data: {accuracy_test * 100:.2f}%\")\n",
    "print(f\"Precision on Test Data: {precision_test * 100:.2f}%\")\n",
    "print(f\"Recall on Test Data: {recall_test * 100:.2f}%\")\n",
    "print(f\"F1-Score on Test Data: {f1_test * 100:.2f}%\")\n",
    "\n",
    "# Generate a detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_binary, y_pred_test))\n",
    "\n",
    "# Generate a confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test_binary, y_pred_test))\n",
    "\n",
    "# Save the trained XGBoost model\n",
    "joblib.dump(xgb_model, 'models_try/xgb_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm Accuracy on Test Data: 63.16%\n",
      "Precision on Test Data: 58.75%\n",
      "Recall on Test Data: 95.92%\n",
      "F1-Score on Test Data: 72.87%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.28      0.43        92\n",
      "           1       0.59      0.96      0.73        98\n",
      "\n",
      "    accuracy                           0.63       190\n",
      "   macro avg       0.73      0.62      0.58       190\n",
      "weighted avg       0.72      0.63      0.58       190\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[26 66]\n",
      " [ 4 94]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models_try/xgb_model.pkl']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the SVM classifier\n",
    "svm_model = SVC(kernel='rbf', random_state=42)  # Using radial basis function kernel\n",
    "\n",
    "# Train the model\n",
    "svm_model.fit(X_train_binary, y_train_binary)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_test = svm_model.predict(X_test_binary)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_test = accuracy_score(y_test_binary, y_pred_test)\n",
    "precision_test = precision_score(y_test_binary, y_pred_test)\n",
    "recall_test = recall_score(y_test_binary, y_pred_test)\n",
    "f1_test = f1_score(y_test_binary, y_pred_test)\n",
    "\n",
    "print(f\"svm Accuracy on Test Data: {accuracy_test * 100:.2f}%\")\n",
    "print(f\"Precision on Test Data: {precision_test * 100:.2f}%\")\n",
    "print(f\"Recall on Test Data: {recall_test * 100:.2f}%\")\n",
    "print(f\"F1-Score on Test Data: {f1_test * 100:.2f}%\")\n",
    "\n",
    "# Generate a detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_binary, y_pred_test))\n",
    "\n",
    "# Generate a confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test_binary, y_pred_test))\n",
    "\n",
    "# Save the trained XGBoost model\n",
    "joblib.dump(xgb_model, 'models_try/xgb_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class  weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##using inverse frequency method\n",
    "\n",
    "class_weights = {\n",
    "    1: 1,     # Majority class 1\n",
    "    4: 1,     # Majority class 4\n",
    "    0: 3,     # Minority class 0\n",
    "    2: 2.5,   # Minority class 2\n",
    "    3: 2      # Minority class 3\n",
    "}\n",
    "\n",
    "\n",
    "class_weights_binary = {\n",
    "    0: 17,     # Minority class \n",
    "    1: 1,     # Majority class \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Classifier Accuracy on Test Data: 93.47%\n",
      "Precision on Test Data: 93.99%\n",
      "Recall on Test Data: 97.99%\n",
      "F1-Score on Test Data: 95.95%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.71      0.80       119\n",
      "           1       0.94      0.98      0.96       539\n",
      "\n",
      "    accuracy                           0.93       658\n",
      "   macro avg       0.92      0.85      0.88       658\n",
      "weighted avg       0.93      0.93      0.93       658\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 85  34]\n",
      " [  9 530]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models_try/binary_rf_model_weights.pkl']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create binary target variable\n",
    "collision_free_data_upsampled['binary_target'] = collision_free_data_upsampled['action'].apply(lambda x: 1 if x in [1,3, 4] else 0)\n",
    "\n",
    "# Split the data into features and target\n",
    "X_binary = collision_free_data_upsampled.drop(columns=['action', 'binary_target'])\n",
    "y_binary = collision_free_data_upsampled['binary_target']\n",
    "\n",
    "# Split the dataset into train, test, and eval sets\n",
    "X_train_binary, X_temp_binary, y_train_binary, y_temp_binary = train_test_split(X_binary, y_binary, test_size=0.2, random_state=42)\n",
    "X_test_binary, X_eval_binary, y_test_binary, y_eval_binary = train_test_split(X_temp_binary, y_temp_binary, test_size=0.5, random_state=42)\n",
    "\n",
    "# Train the binary classifier with class weights\n",
    "binary_rf_model = RandomForestClassifier(class_weight=class_weights_binary, random_state=42)\n",
    "binary_rf_model.fit(X_train_binary, y_train_binary)\n",
    "\n",
    "# Evaluate the binary classifier\n",
    "y_pred_binary_test = binary_rf_model.predict(X_test_binary)\n",
    "accuracy_binary_test = accuracy_score(y_test_binary, y_pred_binary_test)\n",
    "print(f\"Binary Classifier Accuracy on Test Data: {accuracy_binary_test * 100:.2f}%\")\n",
    "print(f\"Precision on Test Data: {precision_test * 100:.2f}%\")\n",
    "print(f\"Recall on Test Data: {recall_test * 100:.2f}%\")\n",
    "print(f\"F1-Score on Test Data: {f1_test * 100:.2f}%\")\n",
    "\n",
    "# Generate a detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_binary, y_pred_binary_test))\n",
    "\n",
    "# Generate a confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test_binary, y_pred_binary_test))\n",
    "\n",
    "# Save the binary classifier\n",
    "joblib.dump(binary_rf_model, 'models_try/binary_rf_model_weights.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "minor action classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9821428571428571\n",
      "Evaluation Accuracy: 0.9910714285714286\n",
      "\n",
      "Classification Report on Test Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98        55\n",
      "         2.0       1.00      0.96      0.98        57\n",
      "\n",
      "    accuracy                           0.98       112\n",
      "   macro avg       0.98      0.98      0.98       112\n",
      "weighted avg       0.98      0.98      0.98       112\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models_try/minor_rf_model_upsampled.pkl']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the data for classes 0, 2,\n",
    "minor_data = collision_free_data_upsampled[collision_free_data_upsampled['binary_target'] == 0]\n",
    "#print(filtered_data[0:5])\n",
    "\n",
    "# Split the dataset into features and target\n",
    "X = minor_data.drop(columns=['action', 'binary_target'])\n",
    "y = minor_data['action']  # Multi-class target\n",
    "\n",
    "# Split into train, test, and eval sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_test, X_eval, y_test, y_eval = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Train a single Random Forest classifier\n",
    "rf_model_minor = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model_minor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_test = rf_model_minor.predict(X_test)\n",
    "y_pred_eval = rf_model_minor.predict(X_eval)\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred_test))\n",
    "print(\"Evaluation Accuracy:\", accuracy_score(y_eval, y_pred_eval))\n",
    "print(\"\\nClassification Report on Test Data:\\n\", classification_report(y_test, y_pred_test))\n",
    "\n",
    "# Save the binary classifier\n",
    "joblib.dump(rf_model_minor, 'models_try/minor_rf_model_upsampled.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "major action classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7104677060133631\n",
      "Evaluation Accuracy: 0.76\n",
      "\n",
      "Classification Report on Test Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.65      0.63      0.64       156\n",
      "         3.0       0.76      0.70      0.73       147\n",
      "         4.0       0.73      0.81      0.77       146\n",
      "\n",
      "    accuracy                           0.71       449\n",
      "   macro avg       0.71      0.71      0.71       449\n",
      "weighted avg       0.71      0.71      0.71       449\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 98  23  35]\n",
      " [ 35 103   9]\n",
      " [ 18  10 118]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models_try/major_rf_model_down_upsampled.pkl']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the data for classes 1 3and 4\n",
    "major_data_down_upsampled = collision_free_data_up_downsampled[collision_free_data_up_downsampled['binary_target'] == 1]\n",
    "#print(filtered_data[0:5])\n",
    "\n",
    "# Split the dataset into features and target\n",
    "X = major_data_down_upsampled.drop(columns=['action', 'binary_target'])\n",
    "y = major_data_down_upsampled['action']  # Multi-class target\n",
    "\n",
    "# Split into train, test, and eval sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_test, X_eval, y_test, y_eval = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Train a single Random Forest classifier\n",
    "rf_model_major = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model_major.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_test = rf_model_major.predict(X_test)\n",
    "y_pred_eval = rf_model_major.predict(X_eval)\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred_test))\n",
    "print(\"Evaluation Accuracy:\", accuracy_score(y_eval, y_pred_eval))\n",
    "print(\"\\nClassification Report on Test Data:\\n\", classification_report(y_test, y_pred_test))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "\n",
    "# Save the binary classifier\n",
    "joblib.dump(rf_model_major, 'models_try/major_rf_model_down_upsampled.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
