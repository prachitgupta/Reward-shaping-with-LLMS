{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils import resample\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data merged and sorted successfully. Saved to datasets_try/merged_sorted_data.csv\n"
     ]
    }
   ],
   "source": [
    "def merge_and_sort_csv(file1, file2, output_file):\n",
    "    # Load the CSV files into pandas DataFrames\n",
    "    df1 = pd.read_csv(file1)\n",
    "    df2 = pd.read_csv(file2)\n",
    "\n",
    "    # Combine the data from both DataFrames\n",
    "    combined_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "    # Sort the combined data by the 'action' column (ascending order)\n",
    "    sorted_df = combined_df.sort_values(by='action', ascending=True)\n",
    "\n",
    "    # Save the sorted data to a new CSV file\n",
    "    sorted_df.to_csv(output_file, index=False)\n",
    "\n",
    "    print(f\"Data merged and sorted successfully. Saved to {output_file}\")\n",
    "\n",
    "# Example usage\n",
    "file1 = 'datasets_try/processed_features5.csv'  # Path to your first CSV file\n",
    "file2 = 'datasets_try/processed_features4.csv'  # Path to your second CSV file\n",
    "output_file = 'datasets_try/merged_sorted_data.csv'  # Output CSV file\n",
    "\n",
    "merge_and_sort_csv(file1, file2, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0    3477\n",
      "4.0    2575\n",
      "3.0     414\n",
      "2.0     307\n",
      "0.0     229\n",
      "Name: action, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('datasets_try/merged_sorted_data.csv')\n",
    "\n",
    "# Check the distribution of the 'action' column\n",
    "action_distribution = data['action'].value_counts()\n",
    "print(action_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Classifier Accuracy on Test Data: 89.29%\n",
      "Precision on Test Data: 91.47%\n",
      "Recall on Test Data: 96.72%\n",
      "F1-Score on Test Data: 94.02%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.39      0.48        90\n",
      "           1       0.91      0.97      0.94       610\n",
      "\n",
      "    accuracy                           0.89       700\n",
      "   macro avg       0.78      0.68      0.71       700\n",
      "weighted avg       0.88      0.89      0.88       700\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 35  55]\n",
      " [ 20 590]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models_try/binary_rf_model.pkl']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a binary target variable\n",
    "data['binary_target'] = data['action'].apply(lambda x: 1 if x in [1, 4] else 0)\n",
    "\n",
    "# Split the data into features and binary target\n",
    "X_binary = data.drop(columns=['action', 'binary_target'])\n",
    "y_binary = data['binary_target']\n",
    "\n",
    "# Split the dataset into train, test, and eval sets\n",
    "X_train_binary, X_temp_binary, y_train_binary, y_temp_binary = train_test_split(X_binary, y_binary, test_size=0.2, random_state=42)\n",
    "X_test_binary, X_eval_binary, y_test_binary, y_eval_binary = train_test_split(X_temp_binary, y_temp_binary, test_size=0.5, random_state=42)\n",
    "\n",
    "# Train the binary classifier\n",
    "binary_rf_model = RandomForestClassifier(random_state=42)\n",
    "binary_rf_model.fit(X_train_binary, y_train_binary)\n",
    "\n",
    "# Evaluate the binary classifier\n",
    "y_pred_binary_test = binary_rf_model.predict(X_test_binary)\n",
    "accuracy_binary_test = accuracy_score(y_test_binary, y_pred_binary_test)\n",
    "print(f\"Binary Classifier Accuracy on Test Data: {accuracy_binary_test * 100:.2f}%\")\n",
    "# Calculate precision, recall, and F1-score\n",
    "precision_test = precision_score(y_test_binary, y_pred_binary_test)\n",
    "recall_test = recall_score(y_test_binary, y_pred_binary_test)\n",
    "f1_test = f1_score(y_test_binary, y_pred_binary_test)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Precision on Test Data: {precision_test * 100:.2f}%\")\n",
    "print(f\"Recall on Test Data: {recall_test * 100:.2f}%\")\n",
    "print(f\"F1-Score on Test Data: {f1_test * 100:.2f}%\")\n",
    "\n",
    "# Generate a detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_binary, y_pred_binary_test))\n",
    "\n",
    "# Generate a confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test_binary, y_pred_binary_test))\n",
    "\n",
    "# Save the binary classifier\n",
    "joblib.dump(binary_rf_model, 'models_try/binary_rf_model.pkl')\n",
    "#print(data[5:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Classifier Accuracy on Test Data: 79.47%\n",
      "Precision on Test Data: 91.47%\n",
      "Recall on Test Data: 96.72%\n",
      "F1-Score on Test Data: 94.02%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.78      0.79        92\n",
      "           1       0.80      0.81      0.80        98\n",
      "\n",
      "    accuracy                           0.79       190\n",
      "   macro avg       0.79      0.79      0.79       190\n",
      "weighted avg       0.79      0.79      0.79       190\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[72 20]\n",
      " [19 79]]\n",
      "1.0    535\n",
      "4.0    415\n",
      "3.0    414\n",
      "2.0    307\n",
      "0.0    229\n",
      "Name: action, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming 'data' is your DataFrame\n",
    "# Create binary target variable\n",
    "data['binary_target'] = data['action'].apply(lambda x: 1 if x in [1, 4] else 0)\n",
    "\n",
    "# Separate majority and minority classes\n",
    "majority_class = data[data['binary_target'] == 1]\n",
    "minority_class = data[data['binary_target'] == 0]\n",
    "\n",
    "# Downsample majority class\n",
    "majority_downsampled = resample(majority_class, \n",
    "                                replace=True,    # Sample without replacement\n",
    "                                n_samples=len(minority_class),  # Match minority class size\n",
    "                                random_state=42)\n",
    "\n",
    "# Combine minority class with downsampled majority class\n",
    "balanced_data = pd.concat([majority_downsampled, minority_class])\n",
    "\n",
    "# Split the balanced data into features and target\n",
    "X_binary = balanced_data.drop(columns=['action', 'binary_target'])\n",
    "y_binary = balanced_data['binary_target']\n",
    "\n",
    "# Split the dataset into train, test, and eval sets\n",
    "X_train_binary, X_temp_binary, y_train_binary, y_temp_binary = train_test_split(X_binary, y_binary, test_size=0.2, random_state=42)\n",
    "X_test_binary, X_eval_binary, y_test_binary, y_eval_binary = train_test_split(X_temp_binary, y_temp_binary, test_size=0.5, random_state=42)\n",
    "\n",
    "# Train the binary classifier\n",
    "binary_rf_model = RandomForestClassifier(random_state=42)\n",
    "binary_rf_model.fit(X_train_binary, y_train_binary)\n",
    "\n",
    "balanced_data.to_csv('datasets_try/downsampled_data.csv', index=False)\n",
    "\n",
    "# Evaluate the binary classifier\n",
    "y_pred_binary_test = binary_rf_model.predict(X_test_binary)\n",
    "accuracy_binary_test = accuracy_score(y_test_binary, y_pred_binary_test)\n",
    "print(f\"Binary Classifier Accuracy on Test Data: {accuracy_binary_test * 100:.2f}%\")\n",
    "\n",
    "print(f\"Precision on Test Data: {precision_test * 100:.2f}%\")\n",
    "print(f\"Recall on Test Data: {recall_test * 100:.2f}%\")\n",
    "print(f\"F1-Score on Test Data: {f1_test * 100:.2f}%\")\n",
    "\n",
    "# Generate a detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_binary, y_pred_binary_test))\n",
    "\n",
    "# Generate a confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test_binary, y_pred_binary_test))\n",
    "\n",
    "\n",
    "# Save the binary classifier\n",
    "joblib.dump(binary_rf_model, 'models_try/binary_rf_model_down.pkl')\n",
    "print(balanced_data['action'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prachit/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [09:03:08] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy on Test Data: 84.27%\n",
      "Precision on Test Data: 82.61%\n",
      "Recall on Test Data: 86.36%\n",
      "F1-Score on Test Data: 84.44%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84        45\n",
      "           1       0.83      0.86      0.84        44\n",
      "\n",
      "    accuracy                           0.84        89\n",
      "   macro avg       0.84      0.84      0.84        89\n",
      "weighted avg       0.84      0.84      0.84        89\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[37  8]\n",
      " [ 6 38]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models_try/xgb_model.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Initialize the XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Train the model\n",
    "xgb_model.fit(X_train_binary, y_train_binary)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_test = xgb_model.predict(X_test_binary)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_test = accuracy_score(y_test_binary, y_pred_test)\n",
    "precision_test = precision_score(y_test_binary, y_pred_test)\n",
    "recall_test = recall_score(y_test_binary, y_pred_test)\n",
    "f1_test = f1_score(y_test_binary, y_pred_test)\n",
    "\n",
    "print(f\"XGBoost Accuracy on Test Data: {accuracy_test * 100:.2f}%\")\n",
    "print(f\"Precision on Test Data: {precision_test * 100:.2f}%\")\n",
    "print(f\"Recall on Test Data: {recall_test * 100:.2f}%\")\n",
    "print(f\"F1-Score on Test Data: {f1_test * 100:.2f}%\")\n",
    "\n",
    "# Generate a detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_binary, y_pred_test))\n",
    "\n",
    "# Generate a confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test_binary, y_pred_test))\n",
    "\n",
    "# Save the trained XGBoost model\n",
    "joblib.dump(xgb_model, 'models_try/xgb_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm Accuracy on Test Data: 75.28%\n",
      "Precision on Test Data: 67.74%\n",
      "Recall on Test Data: 95.45%\n",
      "F1-Score on Test Data: 79.25%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.56      0.69        45\n",
      "           1       0.68      0.95      0.79        44\n",
      "\n",
      "    accuracy                           0.75        89\n",
      "   macro avg       0.80      0.76      0.74        89\n",
      "weighted avg       0.80      0.75      0.74        89\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[25 20]\n",
      " [ 2 42]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models_try/xgb_model.pkl']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the SVM classifier\n",
    "svm_model = SVC(kernel='rbf', random_state=42)  # Using radial basis function kernel\n",
    "\n",
    "# Train the model\n",
    "svm_model.fit(X_train_binary, y_train_binary)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_test = svm_model.predict(X_test_binary)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_test = accuracy_score(y_test_binary, y_pred_test)\n",
    "precision_test = precision_score(y_test_binary, y_pred_test)\n",
    "recall_test = recall_score(y_test_binary, y_pred_test)\n",
    "f1_test = f1_score(y_test_binary, y_pred_test)\n",
    "\n",
    "print(f\"svm Accuracy on Test Data: {accuracy_test * 100:.2f}%\")\n",
    "print(f\"Precision on Test Data: {precision_test * 100:.2f}%\")\n",
    "print(f\"Recall on Test Data: {recall_test * 100:.2f}%\")\n",
    "print(f\"F1-Score on Test Data: {f1_test * 100:.2f}%\")\n",
    "\n",
    "# Generate a detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_binary, y_pred_test))\n",
    "\n",
    "# Generate a confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test_binary, y_pred_test))\n",
    "\n",
    "# Save the trained XGBoost model\n",
    "joblib.dump(xgb_model, 'models_try/xgb_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class  weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Classifier Accuracy on Test Data: 89.14%\n",
      "Precision on Test Data: 91.47%\n",
      "Recall on Test Data: 96.72%\n",
      "F1-Score on Test Data: 94.02%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.36      0.46        90\n",
      "           1       0.91      0.97      0.94       610\n",
      "\n",
      "    accuracy                           0.89       700\n",
      "   macro avg       0.78      0.66      0.70       700\n",
      "weighted avg       0.88      0.89      0.88       700\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 32  58]\n",
      " [ 18 592]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models_try/binary_rf_model.pkl']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create binary target variable\n",
    "data['binary_target'] = data['action'].apply(lambda x: 1 if x in [1, 4] else 0)\n",
    "\n",
    "# Split the data into features and target\n",
    "X_binary = data.drop(columns=['action', 'binary_target'])\n",
    "y_binary = data['binary_target']\n",
    "\n",
    "# Split the dataset into train, test, and eval sets\n",
    "X_train_binary, X_temp_binary, y_train_binary, y_temp_binary = train_test_split(X_binary, y_binary, test_size=0.2, random_state=42)\n",
    "X_test_binary, X_eval_binary, y_test_binary, y_eval_binary = train_test_split(X_temp_binary, y_temp_binary, test_size=0.5, random_state=42)\n",
    "\n",
    "# Train the binary classifier with class weights\n",
    "binary_rf_model = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "binary_rf_model.fit(X_train_binary, y_train_binary)\n",
    "\n",
    "# Evaluate the binary classifier\n",
    "y_pred_binary_test = binary_rf_model.predict(X_test_binary)\n",
    "accuracy_binary_test = accuracy_score(y_test_binary, y_pred_binary_test)\n",
    "print(f\"Binary Classifier Accuracy on Test Data: {accuracy_binary_test * 100:.2f}%\")\n",
    "print(f\"Precision on Test Data: {precision_test * 100:.2f}%\")\n",
    "print(f\"Recall on Test Data: {recall_test * 100:.2f}%\")\n",
    "print(f\"F1-Score on Test Data: {f1_test * 100:.2f}%\")\n",
    "\n",
    "# Generate a detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_binary, y_pred_binary_test))\n",
    "\n",
    "# Generate a confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test_binary, y_pred_binary_test))\n",
    "\n",
    "# Save the binary classifier\n",
    "joblib.dump(binary_rf_model, 'models_try/binary_rf_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "minor action classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   vehicles_in_ego_lane  vehicles_in_left_lane  vehicles_in_right_lane  \\\n",
      "0                   4.0                    1.0                     0.0   \n",
      "1                   4.0                    2.0                     0.0   \n",
      "2                   1.0                    3.0                     0.0   \n",
      "3                   4.0                    0.0                     3.0   \n",
      "4                   6.0                    0.0                     1.0   \n",
      "\n",
      "   closest_in_ego_lane_dist  closest_left_lane_dist  closest_right_lane_dist  \\\n",
      "0                  10.01390                 82.7292                  0.00000   \n",
      "1                  10.74086                 84.2901                  0.00000   \n",
      "2                  50.06064                 22.3463                  0.00000   \n",
      "3                  10.81774              10000.0000                 31.06534   \n",
      "4                  10.85504              10000.0000                 53.04366   \n",
      "\n",
      "   relative_velocity_ego_lane  relative_velocity_left_lane  \\\n",
      "0                   -2.695463                    -1.989330   \n",
      "1                   -2.970257                    -3.048325   \n",
      "2                   -1.635206                    -4.999984   \n",
      "3                   -1.572956                 10000.000000   \n",
      "4                   -2.512188                 10000.000000   \n",
      "\n",
      "   relative_velocity_right_lane  previous_action_1  action  binary_target  \n",
      "0                      0.000000                1.0     0.0              0  \n",
      "1                      0.000000                4.0     0.0              0  \n",
      "2                      0.000000                4.0     0.0              0  \n",
      "3                     -3.195126                4.0     0.0              0  \n",
      "4                     -2.746680                1.0     0.0              0  \n",
      "Test Accuracy: 0.8947368421052632\n",
      "Evaluation Accuracy: 0.9368421052631579\n",
      "\n",
      "Classification Report on Test Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.90      0.90        20\n",
      "         2.0       0.93      0.85      0.89        33\n",
      "         3.0       0.87      0.93      0.90        42\n",
      "\n",
      "    accuracy                           0.89        95\n",
      "   macro avg       0.90      0.89      0.90        95\n",
      "weighted avg       0.90      0.89      0.89        95\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models_try/minor_rf_model.pkl']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the data for classes 0, 2, and 3\n",
    "filtered_data = data[data['binary_target'] == 0]\n",
    "print(filtered_data[0:5])\n",
    "\n",
    "# Split the dataset into features and target\n",
    "X = filtered_data.drop(columns=['action', 'binary_target'])\n",
    "y = filtered_data['action']  # Multi-class target\n",
    "\n",
    "# Split into train, test, and eval sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_test, X_eval, y_test, y_eval = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Train a single Random Forest classifier\n",
    "rf_model_minor = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model_minor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_test = rf_model_minor.predict(X_test)\n",
    "y_pred_eval = rf_model_minor.predict(X_eval)\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred_test))\n",
    "print(\"Evaluation Accuracy:\", accuracy_score(y_eval, y_pred_eval))\n",
    "print(\"\\nClassification Report on Test Data:\\n\", classification_report(y_test, y_pred_test))\n",
    "\n",
    "# Save the binary classifier\n",
    "joblib.dump(rf_model_minor, 'models_try/minor_rf_model.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "major action classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     vehicles_in_ego_lane  vehicles_in_left_lane  vehicles_in_right_lane  \\\n",
      "229                   2.0                    0.0                     1.0   \n",
      "230                   2.0                    0.0                     2.0   \n",
      "231                   2.0                    2.0                     0.0   \n",
      "232                   1.0                    1.0                     4.0   \n",
      "233                   1.0                    4.0                     3.0   \n",
      "\n",
      "     closest_in_ego_lane_dist  closest_left_lane_dist  \\\n",
      "229                  40.09975                 0.00000   \n",
      "230                  42.02866                 0.00000   \n",
      "231                  32.03241                10.65169   \n",
      "232                  32.28675                85.29086   \n",
      "233                  32.70313                22.67897   \n",
      "\n",
      "     closest_right_lane_dist  relative_velocity_ego_lane  \\\n",
      "229                 20.06145                   -2.027105   \n",
      "230                 21.69714                   -1.779930   \n",
      "231                  0.00000                   -1.158371   \n",
      "232                 10.05513                   -2.101010   \n",
      "233                 11.43704                   -2.599154   \n",
      "\n",
      "     relative_velocity_left_lane  relative_velocity_right_lane  \\\n",
      "229                     0.000000                     -3.363540   \n",
      "230                     0.000000                     -1.792776   \n",
      "231                    -2.745811                      0.000000   \n",
      "232                    -3.738762                     -2.147045   \n",
      "233                    -3.246813                     -1.860153   \n",
      "\n",
      "     previous_action_1  action  binary_target  \n",
      "229                1.0     1.0              1  \n",
      "230                4.0     1.0              1  \n",
      "231                4.0     1.0              1  \n",
      "232                4.0     1.0              1  \n",
      "233                4.0     1.0              1  \n",
      "Test Accuracy: 0.8429752066115702\n",
      "Evaluation Accuracy: 0.863036303630363\n",
      "\n",
      "Classification Report on Test Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.87      0.86      0.87       357\n",
      "         4.0       0.80      0.82      0.81       248\n",
      "\n",
      "    accuracy                           0.84       605\n",
      "   macro avg       0.84      0.84      0.84       605\n",
      "weighted avg       0.84      0.84      0.84       605\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models_try/major_rf_model.pkl']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the data for classes 1 and 4\n",
    "filtered_data = data[data['binary_target'] == 1]\n",
    "print(filtered_data[0:5])\n",
    "\n",
    "# Split the dataset into features and target\n",
    "X = filtered_data.drop(columns=['action', 'binary_target'])\n",
    "y = filtered_data['action']  # Multi-class target\n",
    "\n",
    "# Split into train, test, and eval sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_test, X_eval, y_test, y_eval = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Train a single Random Forest classifier\n",
    "rf_model_major = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model_major.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_test = rf_model_major.predict(X_test)\n",
    "y_pred_eval = rf_model_major.predict(X_eval)\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred_test))\n",
    "print(\"Evaluation Accuracy:\", accuracy_score(y_eval, y_pred_eval))\n",
    "print(\"\\nClassification Report on Test Data:\\n\", classification_report(y_test, y_pred_test))\n",
    "\n",
    "# Save the binary classifier\n",
    "joblib.dump(rf_model_major, 'models_try/major_rf_model.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
