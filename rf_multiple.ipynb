{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prachit/.local/lib/python3.8/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils import resample\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data merged and sorted successfully. Saved to datasets_try/collision_free.csv\n"
     ]
    }
   ],
   "source": [
    "def merge_and_sort_csv(file1, file2, output_file):\n",
    "    # Load the CSV files into pandas DataFrames\n",
    "    df1 = pd.read_csv(file1)\n",
    "    df2 = pd.read_csv(file2)\n",
    "    #df3 = pd.read_csv(file3)\n",
    "\n",
    "    # Combine the data from both DataFrames\n",
    "    combined_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "    # Sort the combined data by the 'action' column (ascending order)\n",
    "    sorted_df = combined_df.sort_values(by='action', ascending=True)\n",
    "\n",
    "    # Save the sorted data to a new CSV file\n",
    "    sorted_df.to_csv(output_file, index=False)\n",
    "\n",
    "    print(f\"Data merged and sorted successfully. Saved to {output_file}\")\n",
    "\n",
    "# Example usage\n",
    "file1 = 'datasets_try/processed_features_ml_cl.csv'  # Path to your first CSV file\n",
    "file2 = 'datasets_try/processed_features_all_cl.csv'  # Path to your second CSV file\n",
    "#file3 = 'datasets_try/processed_features_5k.csv'\n",
    "# file4 = 'datasets_try/processed_features_el.csv' \n",
    "output_file = 'datasets_try/collision_free.csv'  # Output CSV file\n",
    "\n",
    "merge_and_sort_csv(file1, file2, output_file)\n",
    "\n",
    "##add more datapoints \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0    2470\n",
      "4.0    1567\n",
      "3.0    1424\n",
      "2.0     411\n",
      "0.0     317\n",
      "Name: action, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "collision_free_data = pd.read_csv('datasets_try/collision_free.csv')\n",
    "\n",
    "# Check the distribution of the 'action' column\n",
    "action_distribution = collision_free_data['action'].value_counts()\n",
    "print(action_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UPSAMPLE MINORITY using dataset fromrandomly generated cenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed and saved the data. Merged dataset saved at datasets_try/collision_free_upsampled.csv\n",
      "1.0    2470\n",
      "4.0    1567\n",
      "3.0    1424\n",
      "2.0     611\n",
      "0.0     506\n",
      "Name: action, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Load the dataset from the file\n",
    "file_path = 'datasets_try/processed_features_5k.csv'\n",
    "file_path2 = 'datasets_try/processed_features_el_cl.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Step 2: Sort the dataset by the action label (last column)\n",
    "# Assuming the action label is the last column\n",
    "df_sorted = df.sort_values(by='action', ascending=True)\n",
    "\n",
    "# Step 3: Extract data points with action label 0 and 2\n",
    "df_label_0 = df_sorted[df_sorted[df.columns[-1]] == 0]\n",
    "df_label_2 = df_sorted[df_sorted[df.columns[-1]] == 2]\n",
    "\n",
    "# Step 4: Save the filtered data to separate CSV files\n",
    "file_label_0 = 'datasets_try/label_0_data.csv'\n",
    "file_label_2 = 'datasets_try/label_2_data.csv'\n",
    "\n",
    "df_label_0.to_csv(file_label_0, index=False)\n",
    "df_label_2.to_csv(file_label_2, index=False)\n",
    "\n",
    "# Step 5: Extract 200 data points from each new CSV and merge them into another CSV\n",
    "# Load the previously saved files\n",
    "df_label_0_loaded = pd.read_csv(file_label_0)\n",
    "df_label_2_loaded = pd.read_csv(file_label_2)\n",
    "\n",
    "# Randomly select 200 data points from each\n",
    "df_label_0_sampled = df_label_0_loaded.sample(n=189, random_state=42)\n",
    "df_label_2_sampled = df_label_2_loaded.sample(n=200, random_state=42)\n",
    "\n",
    "# Step 6: Merge the two sampled dataframes\n",
    "merged_df = pd.concat([df_label_0_sampled, df_label_2_sampled])\n",
    "\n",
    "# Step 7: Load the existing merged dataset if it exists or create a new one\n",
    "input_file_path = 'datasets_try/collision_free.csv'\n",
    "\n",
    "try:\n",
    "    collision_free_data = pd.read_csv(input_file_path)\n",
    "    # Append the new merged data to the existing one\n",
    "    collision_free_data_upsampled = pd.concat([collision_free_data, merged_df])\n",
    "except FileNotFoundError:\n",
    "    # If the file does not exist, create a new one\n",
    "    collision_free_data = merged_df\n",
    "\n",
    "# Step 8: Save the merged data back into the CSV\n",
    "collision_free_data.to_csv('datasets_try/collision_free_upsampled.csv', index=False)\n",
    "\n",
    "print(f\"Successfully processed and saved the data. Merged dataset saved at datasets_try/collision_free_upsampled.csv\") \n",
    "\n",
    "action_distribution = collision_free_data_upsampled['action'].value_counts()\n",
    "print(action_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Classifier Accuracy on Test Data: 93.72%\n",
      "Precision on Test Data: 93.96%\n",
      "Recall on Test Data: 98.63%\n",
      "F1-Score on Test Data: 96.24%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.72      0.81       182\n",
      "           1       0.94      0.99      0.96       805\n",
      "\n",
      "    accuracy                           0.94       987\n",
      "   macro avg       0.93      0.85      0.89       987\n",
      "weighted avg       0.94      0.94      0.93       987\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[131  51]\n",
      " [ 11 794]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models_try/binary_rf_model_collision_free_upsampled.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a binary target variable\n",
    "collision_free_data_upsampled['binary_target'] = collision_free_data_upsampled['action'].apply(lambda x: 1 if x in [1,3, 4] else 0)\n",
    "\n",
    "# Split the data into features and binary target\n",
    "X_binary = collision_free_data_upsampled.drop(columns=['action', 'binary_target'])\n",
    "y_binary = collision_free_data_upsampled['binary_target']\n",
    "\n",
    "# Split the dataset into train, test, and eval sets\n",
    "X_train_binary, X_temp_binary, y_train_binary, y_temp_binary = train_test_split(X_binary, y_binary, test_size=0.3, random_state=42)\n",
    "X_test_binary, X_eval_binary, y_test_binary, y_eval_binary = train_test_split(X_temp_binary, y_temp_binary, test_size=0.5, random_state=42)\n",
    "\n",
    "# Train the binary classifier\n",
    "binary_rf_model = RandomForestClassifier(random_state=42)\n",
    "binary_rf_model.fit(X_train_binary, y_train_binary)\n",
    "\n",
    "# Evaluate the binary classifier\n",
    "y_pred_binary_test = binary_rf_model.predict(X_test_binary)\n",
    "accuracy_binary_test = accuracy_score(y_test_binary, y_pred_binary_test)\n",
    "print(f\"Binary Classifier Accuracy on Test Data: {accuracy_binary_test * 100:.2f}%\")\n",
    "# Calculate precision, recall, and F1-score\n",
    "precision_test = precision_score(y_test_binary, y_pred_binary_test)\n",
    "recall_test = recall_score(y_test_binary, y_pred_binary_test)\n",
    "f1_test = f1_score(y_test_binary, y_pred_binary_test)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Precision on Test Data: {precision_test * 100:.2f}%\")\n",
    "print(f\"Recall on Test Data: {recall_test * 100:.2f}%\")\n",
    "print(f\"F1-Score on Test Data: {f1_test * 100:.2f}%\")\n",
    "\n",
    "# Generate a detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_binary, y_pred_binary_test))\n",
    "\n",
    "# Generate a confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test_binary, y_pred_binary_test))\n",
    "\n",
    "# Save the binary classifier\n",
    "joblib.dump(binary_rf_model, 'models_try/binary_rf_model_collision_free_upsampled.pkl')\n",
    "#print(data[5:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0    1567\n",
      "1.0    1500\n",
      "3.0    1424\n",
      "2.0     611\n",
      "0.0     506\n",
      "Name: action, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "collision_free_data_upsampled['binary_target'] = collision_free_data_upsampled['action'].apply(lambda x: 1 if x in [1, 3,4] else 0)\n",
    "\n",
    "# Separate majority and minority classes\n",
    "majority_class = collision_free_data_upsampled[collision_free_data_upsampled['binary_target'] == 1]\n",
    "minority_class = collision_free_data_upsampled[collision_free_data_upsampled['binary_target'] == 0]\n",
    "idle_class = collision_free_data_upsampled[collision_free_data_upsampled['action'] == 1]\n",
    "non_ideal_class = collision_free_data_upsampled[collision_free_data_upsampled['action'] != 1]\n",
    "\n",
    "# Downsample majority class\n",
    "idle_downsampled = resample(idle_class, \n",
    "                                replace=True,    # Sample without replacement\n",
    "                                n_samples=1500,  # Match minority class size\n",
    "                                random_state=42)\n",
    "collision_free_data_up_downsampled = pd.concat([idle_downsampled, non_ideal_class])\n",
    "\n",
    "print(collision_free_data_up_downsampled['action'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Classifier Accuracy on Test Data: 93.40%\n",
      "Precision on Test Data: 93.99%\n",
      "Recall on Test Data: 97.99%\n",
      "F1-Score on Test Data: 95.95%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.75      0.82       114\n",
      "           1       0.94      0.98      0.96       447\n",
      "\n",
      "    accuracy                           0.93       561\n",
      "   macro avg       0.92      0.87      0.89       561\n",
      "weighted avg       0.93      0.93      0.93       561\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 86  28]\n",
      " [  9 438]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models_try/binary_rf_model_collision_free_up_down.pkl']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a binary target variable\n",
    "collision_free_data_up_downsampled['binary_target'] = collision_free_data_up_downsampled['action'].apply(lambda x: 1 if x in [1,3, 4] else 0)\n",
    "\n",
    "# Split the data into features and binary target\n",
    "X_binary = collision_free_data_up_downsampled.drop(columns=['action', 'binary_target'])\n",
    "y_binary = collision_free_data_up_downsampled['binary_target']\n",
    "\n",
    "# Split the dataset into train, test, and eval sets\n",
    "X_train_binary, X_temp_binary, y_train_binary, y_temp_binary = train_test_split(X_binary, y_binary, test_size=0.2, random_state=42)\n",
    "X_test_binary, X_eval_binary, y_test_binary, y_eval_binary = train_test_split(X_temp_binary, y_temp_binary, test_size=0.5, random_state=42)\n",
    "\n",
    "# Train the binary classifier\n",
    "binary_rf_model = RandomForestClassifier(random_state=42)\n",
    "binary_rf_model.fit(X_train_binary, y_train_binary)\n",
    "\n",
    "# Evaluate the binary classifier\n",
    "y_pred_binary_test = binary_rf_model.predict(X_test_binary)\n",
    "accuracy_binary_test = accuracy_score(y_test_binary, y_pred_binary_test)\n",
    "print(f\"Binary Classifier Accuracy on Test Data: {accuracy_binary_test * 100:.2f}%\")\n",
    "# Calculate precision, recall, and F1-score\n",
    "precision_test = precision_score(y_test_binary, y_pred_binary_test)\n",
    "recall_test = recall_score(y_test_binary, y_pred_binary_test)\n",
    "f1_test = f1_score(y_test_binary, y_pred_binary_test)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Precision on Test Data: {precision_test * 100:.2f}%\")\n",
    "print(f\"Recall on Test Data: {recall_test * 100:.2f}%\")\n",
    "print(f\"F1-Score on Test Data: {f1_test * 100:.2f}%\")\n",
    "\n",
    "# Generate a detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_binary, y_pred_binary_test))\n",
    "\n",
    "# Generate a confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test_binary, y_pred_binary_test))\n",
    "\n",
    "# Save the binary classifier\n",
    "joblib.dump(binary_rf_model, 'models_try/binary_rf_model_collision_free_up_down.pkl')\n",
    "#print(data[5:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prachit/.local/lib/python3.8/site-packages/xgboost/core.py:158: UserWarning: [22:02:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m xgb_model \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mXGBClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, use_label_encoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogloss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_binary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_binary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Make predictions on the test set\u001b[39;00m\n\u001b[1;32m      8\u001b[0m y_pred_test \u001b[38;5;241m=\u001b[39m xgb_model\u001b[38;5;241m.\u001b[39mpredict(X_test_binary)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/xgboost/core.py:738\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    737\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 738\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/xgboost/sklearn.py:1531\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[1;32m   1511\u001b[0m model, metric, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(xgb_model, params)\n\u001b[1;32m   1512\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[1;32m   1513\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[1;32m   1514\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1528\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[1;32m   1529\u001b[0m )\n\u001b[0;32m-> 1531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1532\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1534\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1536\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1537\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1539\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[1;32m   1546\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/xgboost/core.py:738\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    737\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 738\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/xgboost/core.py:2113\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2112\u001b[0m     _check_call(\n\u001b[0;32m-> 2113\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2114\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[1;32m   2115\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2116\u001b[0m     )\n\u001b[1;32m   2117\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2118\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize the XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# Train the model\n",
    "xgb_model.fit(X_train_binary, y_train_binary)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_test = xgb_model.predict(X_test_binary)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_test = accuracy_score(y_test_binary, y_pred_test)\n",
    "precision_test = precision_score(y_test_binary, y_pred_test)\n",
    "recall_test = recall_score(y_test_binary, y_pred_test)\n",
    "f1_test = f1_score(y_test_binary, y_pred_test)\n",
    "\n",
    "print(f\"XGBoost Accuracy on Test Data: {accuracy_test * 100:.2f}%\")\n",
    "print(f\"Precision on Test Data: {precision_test * 100:.2f}%\")\n",
    "print(f\"Recall on Test Data: {recall_test * 100:.2f}%\")\n",
    "print(f\"F1-Score on Test Data: {f1_test * 100:.2f}%\")\n",
    "\n",
    "# Generate a detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_binary, y_pred_test))\n",
    "\n",
    "# Generate a confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test_binary, y_pred_test))\n",
    "\n",
    "# Save the trained XGBoost model\n",
    "joblib.dump(xgb_model, 'models_try/xgb_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm Accuracy on Test Data: 87.84%\n",
      "Precision on Test Data: 87.56%\n",
      "Recall on Test Data: 99.26%\n",
      "F1-Score on Test Data: 93.04%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.36      0.52       119\n",
      "           1       0.88      0.99      0.93       539\n",
      "\n",
      "    accuracy                           0.88       658\n",
      "   macro avg       0.90      0.68      0.72       658\n",
      "weighted avg       0.88      0.88      0.86       658\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 43  76]\n",
      " [  4 535]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models_try/xgb_model.pkl']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the SVM classifier\n",
    "svm_model = SVC(kernel='rbf', random_state=42)  # Using radial basis function kernel\n",
    "\n",
    "# Train the model\n",
    "svm_model.fit(X_train_binary, y_train_binary)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_test = svm_model.predict(X_test_binary)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_test = accuracy_score(y_test_binary, y_pred_test)\n",
    "precision_test = precision_score(y_test_binary, y_pred_test)\n",
    "recall_test = recall_score(y_test_binary, y_pred_test)\n",
    "f1_test = f1_score(y_test_binary, y_pred_test)\n",
    "\n",
    "print(f\"svm Accuracy on Test Data: {accuracy_test * 100:.2f}%\")\n",
    "print(f\"Precision on Test Data: {precision_test * 100:.2f}%\")\n",
    "print(f\"Recall on Test Data: {recall_test * 100:.2f}%\")\n",
    "print(f\"F1-Score on Test Data: {f1_test * 100:.2f}%\")\n",
    "\n",
    "# Generate a detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_binary, y_pred_test))\n",
    "\n",
    "# Generate a confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test_binary, y_pred_test))\n",
    "\n",
    "# Save the trained XGBoost model\n",
    "joblib.dump(xgb_model, 'models_try/xgb_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class  weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "##using inverse frequency method\n",
    "\n",
    "class_weights = {\n",
    "    1: 1,     # Majority class 1\n",
    "    4: 1,     # Majority class 4\n",
    "    0: 3,     # Minority class 0\n",
    "    2: 2.5,   # Minority class 2\n",
    "    3: 2      # Minority class 3\n",
    "}\n",
    "\n",
    "\n",
    "class_weights_binary = {\n",
    "    0: 17,     # Minority class \n",
    "    1: 1,     # Majority class \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Classifier Accuracy on Test Data: 93.47%\n",
      "Precision on Test Data: 93.99%\n",
      "Recall on Test Data: 97.99%\n",
      "F1-Score on Test Data: 95.95%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.71      0.80       119\n",
      "           1       0.94      0.98      0.96       539\n",
      "\n",
      "    accuracy                           0.93       658\n",
      "   macro avg       0.92      0.85      0.88       658\n",
      "weighted avg       0.93      0.93      0.93       658\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 85  34]\n",
      " [  9 530]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models_try/binary_rf_model_weights.pkl']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create binary target variable\n",
    "collision_free_data_upsampled['binary_target'] = collision_free_data_upsampled['action'].apply(lambda x: 1 if x in [1,3, 4] else 0)\n",
    "\n",
    "# Split the data into features and target\n",
    "X_binary = collision_free_data_upsampled.drop(columns=['action', 'binary_target'])\n",
    "y_binary = collision_free_data_upsampled['binary_target']\n",
    "\n",
    "# Split the dataset into train, test, and eval sets\n",
    "X_train_binary, X_temp_binary, y_train_binary, y_temp_binary = train_test_split(X_binary, y_binary, test_size=0.2, random_state=42)\n",
    "X_test_binary, X_eval_binary, y_test_binary, y_eval_binary = train_test_split(X_temp_binary, y_temp_binary, test_size=0.5, random_state=42)\n",
    "\n",
    "# Train the binary classifier with class weights\n",
    "binary_rf_model = RandomForestClassifier(class_weight=class_weights_binary, random_state=42)\n",
    "binary_rf_model.fit(X_train_binary, y_train_binary)\n",
    "\n",
    "# Evaluate the binary classifier\n",
    "y_pred_binary_test = binary_rf_model.predict(X_test_binary)\n",
    "accuracy_binary_test = accuracy_score(y_test_binary, y_pred_binary_test)\n",
    "print(f\"Binary Classifier Accuracy on Test Data: {accuracy_binary_test * 100:.2f}%\")\n",
    "print(f\"Precision on Test Data: {precision_test * 100:.2f}%\")\n",
    "print(f\"Recall on Test Data: {recall_test * 100:.2f}%\")\n",
    "print(f\"F1-Score on Test Data: {f1_test * 100:.2f}%\")\n",
    "\n",
    "# Generate a detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_binary, y_pred_binary_test))\n",
    "\n",
    "# Generate a confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test_binary, y_pred_binary_test))\n",
    "\n",
    "# Save the binary classifier\n",
    "joblib.dump(binary_rf_model, 'models_try/binary_rf_model_weights.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "minor action classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9821428571428571\n",
      "Evaluation Accuracy: 0.9910714285714286\n",
      "\n",
      "Classification Report on Test Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98        55\n",
      "         2.0       1.00      0.96      0.98        57\n",
      "\n",
      "    accuracy                           0.98       112\n",
      "   macro avg       0.98      0.98      0.98       112\n",
      "weighted avg       0.98      0.98      0.98       112\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[55  0]\n",
      " [ 2 55]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models_try/minor_rf_model_upsampled.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the data for classes 0, 2,\n",
    "minor_data = collision_free_data_upsampled[collision_free_data_upsampled['binary_target'] == 0]\n",
    "#print(filtered_data[0:5])\n",
    "\n",
    "# Split the dataset into features and target\n",
    "X = minor_data.drop(columns=['action', 'binary_target'])\n",
    "y = minor_data['action']  # Multi-class target\n",
    "\n",
    "# Split into train, test, and eval sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_test, X_eval, y_test, y_eval = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Train a single Random Forest classifier\n",
    "rf_model_minor = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model_minor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_test = rf_model_minor.predict(X_test)\n",
    "y_pred_eval = rf_model_minor.predict(X_eval)\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred_test))\n",
    "print(\"Evaluation Accuracy:\", accuracy_score(y_eval, y_pred_eval))\n",
    "print(\"\\nClassification Report on Test Data:\\n\", classification_report(y_test, y_pred_test))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "\n",
    "# Save the binary classifier\n",
    "joblib.dump(rf_model_minor, 'models_try/minor_rf_model_upsampled.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "major action classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##using all data for 1-3-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered dataset saved as 'filtered_dataset.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def filter_data(file_path, labels_to_extract):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Check if the 'action' column exists\n",
    "    if 'action' not in df.columns:\n",
    "        raise ValueError(f\"The 'action' column is missing in the file: {file_path}\")\n",
    "    \n",
    "    # Filter the dataframe based on the action label\n",
    "    filtered_df = df[df['action'].isin(labels_to_extract)]\n",
    "    return filtered_df\n",
    "\n",
    "# Function to process multiple CSV files and merge the data\n",
    "def process_datasets(file_paths, labels_to_extract):\n",
    "    all_filtered_data = []\n",
    "    \n",
    "    # Process each dataset\n",
    "    for file_path in file_paths:\n",
    "        filtered_data = filter_data(file_path, labels_to_extract)\n",
    "        all_filtered_data.append(filtered_data)\n",
    "    \n",
    "    # Combine all the filtered data into a single dataframe\n",
    "    combined_data = pd.concat(all_filtered_data, ignore_index=True)\n",
    "    return combined_data\n",
    "\n",
    "# List of file paths (you can add/remove paths as needed)\n",
    "file_paths = [\n",
    "    'datasets_try/collision_free.csv',  # Add paths to your CSV files\n",
    "    'datasets_try/processed_features_5k.csv',\n",
    "    # 'datasets_try/processed_features_el_cl.csv'\n",
    "    # 'dataset4.csv',\n",
    "    # 'dataset5.csv'\n",
    "]\n",
    "\n",
    "# Define labels to extract\n",
    "labels_to_extract = [1, 3, 4]\n",
    "\n",
    "# Process the datasets and create the new dataset\n",
    "new_dataset = process_datasets(file_paths, labels_to_extract)\n",
    "\n",
    "# Save the new dataset to a CSV file\n",
    "new_dataset.to_csv('datasets_try/major.csv', index=False)\n",
    "\n",
    "print(\"Filtered dataset saved as 'filtered_dataset.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0    4945\n",
      "4.0    3648\n",
      "3.0    1453\n",
      "Name: action, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "major_data = pd.read_csv('datasets_try/major.csv')\n",
    "\n",
    "# Check the distribution of the 'action' column\n",
    "action_distribution =major_data['action'].value_counts()\n",
    "print(action_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0    1453\n",
      "4.0    1453\n",
      "3.0    1453\n",
      "Name: action, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "slow_class = major_data[major_data['action'] == 4]\n",
    "idle_class = major_data[major_data['action'] == 1]\n",
    "fast_class =major_data[major_data['action'] == 3]\n",
    "\n",
    "# Downsample majority class\n",
    "idle_downsampled = resample(idle_class, \n",
    "                                replace=True,    # Sample without replacement\n",
    "                                n_samples=1453,  # Match minority class size\n",
    "                                random_state=42)\n",
    "slow_downsampled = resample(slow_class, \n",
    "                                replace=True,    # Sample without replacement\n",
    "                                n_samples=1453,  # Match minority class size\n",
    "                                random_state=42)\n",
    "\n",
    "fast_downsampled = resample(fast_class, \n",
    "                                replace=True,    # Sample without replacement\n",
    "                                n_samples=1453,  # Match minority class size\n",
    "                                random_state=42)\n",
    "major_downsampled = pd.concat([idle_downsampled, slow_downsampled, fast_downsampled])\n",
    "\n",
    "print(major_downsampled['action'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8165137614678899\n",
      "Evaluation Accuracy: 0.8165137614678899\n",
      "\n",
      "Classification Report on Test Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.78      0.77      0.78       159\n",
      "         3.0       0.81      0.87      0.84       129\n",
      "         4.0       0.86      0.82      0.84       148\n",
      "\n",
      "    accuracy                           0.82       436\n",
      "   macro avg       0.82      0.82      0.82       436\n",
      "weighted avg       0.82      0.82      0.82       436\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[123  21  15]\n",
      " [ 13 112   4]\n",
      " [ 22   5 121]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['models_try/major_rf_model_down_upsampled.pkl']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Filter the data for classes 1 3and 4\n",
    "# major_data_down_upsampled = collision_free_data_up_downsampled[collision_free_data_up_downsampled['binary_target'] == 1]\n",
    "# #print(filtered_data[0:5])\n",
    "\n",
    "# Split the dataset into features and target\n",
    "# X = new_dataset.drop(columns=['action', 'binary_target'])\n",
    "X = major_downsampled.drop(columns=['action'])\n",
    "y = major_downsampled['action']  # Multi-class target\n",
    "\n",
    "# Split into train, test, and eval sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_test, X_eval, y_test, y_eval = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Train a single Random Forest classifier\n",
    "rf_model_major = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model_major.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_test = rf_model_major.predict(X_test)\n",
    "y_pred_eval = rf_model_major.predict(X_eval)\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred_test))\n",
    "print(\"Evaluation Accuracy:\", accuracy_score(y_eval, y_pred_eval))\n",
    "print(\"\\nClassification Report on Test Data:\\n\", classification_report(y_test, y_pred_test))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_test))\n",
    "\n",
    "# Save the binary classifier\n",
    "joblib.dump(rf_model_major, 'models_try/major_rf_model_down_upsampled.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
